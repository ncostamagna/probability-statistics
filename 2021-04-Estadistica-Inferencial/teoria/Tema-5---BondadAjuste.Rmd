---
title: "Tema 5 - Bondad de Ajuste"
author: "Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir"
date: 
output: 
  ioslides_presentation:
    widescreen: true
    css: Mery_style.css
    logo: Images/matriz_mov.gif
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Contrastes no paramétricos

## Introducción 

En el capítulo anterior hemos visto toda una batería de contrastes de hipótesis basados en parámetros de poblaciones como por ejemplo $\mu$, media de la población, $p$, proporción de éxitos de la población, $\sigma$, desviación típica de la población, etc.

En este tipo de contrastes, suponemos que conocemos el tipo de distribución de la población. O sea, sabemos que la variable $X$, que nos da los valores de la población, es normal, binomial, o de otro tipo. Lo que no conocemos, y ésta es la razón de por qué realizamos este tipo de contrastes, es uno o más parámetros de los que depende la distribución de la variable $X$.

Por ejemplo, si suponemos que $X$ es normal y hacemos contrastes de hipótesis sobre su media, tenemos, por un lado, el caso en que conocemos la desviación típica $\sigma$ y el caso en que no la conocemos. 

## Introducción 
A todo este tipo de contrastes se les conoce como **contrastes paramétricos**.

Ahora bien, suponer de qué tipo es la distribución de la variable $X$ que nos da los valores de la población es de hecho "un brindis al sol".
¿En qué nos basamos en decir que la distribución de $X$ es normal por ejemplo? ¿Qué evidencias basadas en información sobre los valores de una muestra de dicha población tenemos de la normalidad de $X$?

Este tipo de preguntas son las que intentan responder los **contrastes no paramétricos**. Son contrastes en los que la hipótesis nula no consiste en averiguar si un determinado parámetro vale un cierto valor sino que la distribución de la variable $X$ es de un tipo u otro. 
Una vez que tengamos evidencias suficientes de la normalidad de $X$, podemos pasar a una "segunda fase" e intentar saber alguna información sobre los parámetros de los que depende la distribución de $X$ usando los **contrastes paramétricos**.

# Contrastes de bondad de ajuste 

## Introducción

Uno de las técnicas más conocidas para estudiar los **contrastes no paramétricos** son los **tests de bondad de ajuste** o **tests $\chi^2$**.

El contraste que intentamos estudiar es del tipo siguiente:
$$
\left.
\begin{array}{ll}
H_0: \mbox{ La distribución de $X$ es del tipo $X_0$,}\\
H_1: \mbox{ La distribución de $X$ no es del tipo $X_0$,}
\end{array}
\right\}
$$
donde $X_0$ es un tipo de distribución conocida. 

<l class="observ">Observación:</l> en la distribución de $X_0$ no hace falta indicar los parámetros de los que ésta depende. Por ejemplo, $X_0$ puede ser normal, binomial, Poisson, etc. pero no indicamos los parámetros de los que depende. Veremos más adelante cómo estimar o aproximar dichos parámetros a partir de los valores de la muestra.

## Pruebas gráficas: histogramas
Supongamos que nuestra variable $X_0$ es continua.

Para comprobar si una determinada muestra proviene de la variable $X_0$, lo primero que podemos hacer es realizar distintas pruebas gráficas como por ejemplo histogramas. 

A partir de dichos histogramas, podemos "estimar" la función de densidad de la muestra y ver si dicha función de densidad se parece o no a la función de densidad de la variable $X_0$.

La estimación de la función de densidad a partir del histograma de la muestra se sale de los objetivos del curso pero vamos a ver con un ejemplo cómo podemos usar dicha función. Si queréis detalles, consultad https://en.wikipedia.org/wiki/Kernel_density_estimation.


## Pruebas gráficas: histogramas
<div class="example">
**Ejemplo**

Consideremos la tabla de datos `iris`, concretamente la variable anchura del sépalo (`Sepal.Width`).

Queremos ver a qué se puede aproximar dicha variable. 

Vamos a realizar un gráfico de la estimación de la función de densidad de la muestra usando la función `density` de `R`:

```{r,fig.align='center',eval=FALSE}
muestra=iris$Sepal.Width
plot(density(muestra),main="Estimación de la densidad")
```

</div>

## Pruebas gráficas: histogramas
<div class="example">

```{r,fig.align='center',echo=FALSE}
muestra=iris$Sepal.Width
plot(density(muestra),main="Estimación de la densidad")
```

</div>

## Pruebas gráficas: histogramas
<div class="example">
A "ojo de buen cubero", parece una campana de Gauss. Para comprobarlo, dibujemos además la función de densidad de la distribución normal con parámetros $\mu$ igualado a la media de la muestra y $\sigma$, a la desviación típica:

```{r,fig.align='center',eval=FALSE}
muestra=iris$Sepal.Width
plot(density(muestra),main="Estimación de la densidad")
x=seq(from=1,to=5,by=0.01)
mu=mean(iris$Sepal.Width)
sigma=sd(iris$Sepal.Width)
lines(x,dnorm(x,mean=mu,sd=sigma),col="red")
```

</div>


## Pruebas gráficas: histogramas
<div class="example">
```{r,fig.align='center',echo=FALSE}
muestra=iris$Sepal.Width
plot(density(muestra),main="Estimación de la densidad")
x=seq(from=1,to=5,by=0.01)
mu=mean(iris$Sepal.Width)
sigma=sd(iris$Sepal.Width)
lines(x,dnorm(x,mean=mu,sd=sigma),col="red")
```

</div>

## Pruebas gráficas: histogramas
<div class="example">
Vemos que la campana de Gauss se parece bastante a la estimación de la densidad. 

La cuestión ahora es: ¿podemos aceptar que el parecido es suficiente para aceptar que la distribución de la anchura del sépalo es normal?

La respuesta será contestada en secciones posteriores.
</div>


## Pruebas gráficas: Q-Q-plots
Otro tipo de prueba gráfica que podemos realizar son los llamados **gráficos cuantil-cuantil o Q-Q-plots**.

Este tipo de gráficos compara  los **cuantiles observados de la muestra** con los **cuantiles teóricos de la distribución teórica.**

La función de `R` que realiza un gráfico de este tipo es la función `qqPlot` del paquete `car`. 

 Su sintaxis básica es
```{r, eval=FALSE}
qqPlot(x, distribution=...,  parámetros, id=FALSE, ...)
```
donde:

## Pruebas gráficas: Q-Q-plots
* `x` es el vector con la muestra.

* El parámetro `distribution` se ha de igualar al nombre de la familia de distribuciones  entre comillas, y puede tomar como valor cualquier familia de distribuciones de la que R sepa calcular la densidad y los cuantiles: esto incluye  las distribuciones que hemos estudiado hasta el momento: `"norm"`, `"binom"`, `"poisson"`, `"t"`, etc.

*  A continuación, se tienen que entrar los parámetros de la distribución, igualando su nombre habitual (`mean` para la media, `sd` para la desviación típica, `df` para los grados de libertad, etc.)  a su valor.

* Por defecto, el gráfico obtenido con la función `qqPlot` identifica los dos Q-Q-puntos con ordenadas más extremas. Para omitirlos, usad el parámetro `id=FALSE`.


## Pruebas gráficas: Q-Q-plots
Otros parámetros a tener en cuenta:

* `qqPlot` añade por defecto una rejilla al gráfico, que podéis eliminar con `grid=FALSE`.


*  `qqPlot` añade por defecto una línea recta que une los Q-Q-puntos correspondientes al  primer y tercer cuartil: se la llama **recta cuartil-cuartil**. Un buen ajuste de los Q-Q-puntos a esta recta significa que la muestra se ajusta a la distribución teórica, pero posiblemente con parámetros diferentes a los especificados. Os recomendamos mantenerla, pero si queréis eliminarla por ejemplo para substituirla por la diagonal $y=x$, podéis usar el parámetro `line="none"`.

## Pruebas gráficas: Q-Q-plots

* `qqPlot` también añade dos curvas discontinuas que abrazan una "región de confianza del 95%" para el Q-Q-plot. Sin entrar en detalles, esta región contendría todos los Q-Q-puntos en un 95% de las ocasiones que tomáramos una muestra de la distribución teórica del mismo tamaño que la nuestra. Por lo tanto, si todos los Q-Q-puntos caen dentro de esta franja, no hay evidencia para rechazar que la muestra provenga de la distribución teórica. Esta franja de confianza es muy útil para interpretar el Q-Q-plot, pero la podéis eliminar con `envelope=FALSE`.

* Se pueden usar los parámetros usuales de `plot` para poner nombres a los ejes, título, modificar el estilo de los puntos, etc., y otros parámetros específicos para modificar el aspecto del gráfico.  Por ejemplo, `col.lines` sirve para especificar el color de las líneas  que añade.




Hagamos un gráfico Q-Q-plot del ejemplo anterior.


## Pruebas gráficas: Q-Q-plots
<div class="example">
**Ejemplo**

Recordemos que considerábamos la variable anchura del sépalo de la tabla de datos `iris`.

El Q-Q-plot para ver si la variable anterior sigue la ley normal es el siguiente:

```{r,eval=FALSE}
library(car)
qqPlot(iris$Sepal.Width,distribution = "norm", mean=mu,sd=sigma)
```

</div>

## Pruebas gráficas: Q-Q-plots
<div class="example">

```{r,echo=FALSE,fig.align='center',message=FALSE}
library(car)
qqPlot(iris$Sepal.Width,distribution = "norm", mean=mu,sd=sigma)
```

</div>


## Pruebas gráficas: Q-Q-plots
<div class="example">
Observamos que la mayoría de los valores de la muestra caen dentro de la franja del 95% de confianza. 

Sin embargo, fijaros que hay unos pocos puntos que se salen de dicha franja.

En resumen, según esta prueba gráfica, "parece" que la distribución es normal pero tenemos dudas.

</div>

## Contraste $\chi^2$ de Pearson
Veamos a continuación cómo se realiza un **contraste $\chi^2$ de Pearson**.

Suponemos que disponemos de los valores de una muestra de tamaño $n$ de la variable $X$ que nos da los valores de la población: $x_1,x_2,\ldots,x_n$.

A continuación, clasificamos los valores $x_i$, $i=1,\ldots, n$ en $k$ clases. La elección de estas clases depende del problema estudiado y del contexto del mismo. 

Sean $n_1,\ldots,n_k$, el número de valores de la muestra que están en cada una de las clases: $n_1$ sería el número de valores de la muestra que están en la clase 1, $n_2$, el número de valores de la muestra que están en la clase 2 y así sucesivamente hasta $n_k$.

## Contraste $\chi^2$ de Pearson
Obtendríamos lo que se conoce como **tabla de frecuencias empíricas**:

<div class="center">
| Clases | Clase 1    | Clase 2 | $\ldots$ | Clase $k$ | Total |
|:----|:----:|:----:|:----:|:----:|:----:|
| Frecuencias empíricas   | $n_1$ | $n_2$ | $\ldots$ | $n_k$ | $n$
</div>

El siguiente paso es obtener la tabla de la función de probabilidad de la variable discreta $X_k$ de valores $\{1,\ldots,k\}$ y con función de probabilidad $p_i=P(X_k=i)=P(X_0\in\mbox{Clase i})$, $i=1,\ldots,k$.

Esta función de probabilidad tiene que hallarse a partir del conocimiento de $X_0$. Si desconocemos alguno(s) del (de los) parámetro(s) de (los) que depende $X_0$, los tendremos que estimar usando las técnicas vistas en el capítulo de estimación de parámetros.


## Contraste $\chi^2$ de Pearson
La tabla de la función de probabilidad $X_k$ quedaría de la forma siguiente:
<div class="center">
| $X_k$ | $1$    | $2$ | $\ldots$ | $k$ | Total |
|:----|:----:|:----:|:----:|:----:|:----:|
| $P(X_k=i)$   | $P(X_k=1)$ | $P(X_k=2)$ | $\ldots$ | $P(X_k=k)$ | $1$
</div>

A partir de dicha tabla, calculamos la **tabla de frecuencias teóricas**: 
<div class="center">
| Clases | Clase 1    | Clase 2 | $\ldots$ | Clase $k$ | Total |
|:----|:----:|:----:|:----:|:----:|:----:|
| Frecuencias teóricas  | $n\cdot P(X_k=1)$ | $n\cdot P(X_k=2)$ | $\ldots$ | $n\cdot P(X_k=k)$ | $n$
| Frecuencias teóricas  | $e_1$ | $e_2$ | $\ldots$ | $e_k$ | $n$
</div>

Llamaremos $e_i=n\cdot P(X_k=i)$ a la **frecuencia teórica** de la clase $i$-ésima. ($e$ de "esperada")



## Contraste $\chi^2$ de Pearson
El **test $\chi^2$** o **test de bondad de ajuste** se basa en que, si la hipótesis nula es cierta, las **frecuencias empíricas** y las **frecuencias teóricas** son "parecidas".

Más concretamente, si la hipótesis nula es cierta, el estadístico siguiente:
$$
\chi^2 = \sum_{i=1}^k \frac{(\mbox{frec. empíricas}_i-\mbox{frec. teóricas}_i)^2}{\mbox{frec. teóricas}_i}= \sum_{i=1}^k \frac{(n_i-e_i)^2}{e_i},
$$
sigue aproximadamente al distribución $\chi^2_{k-1}$ grados de libertad. 

Sea $\chi_0$ el valor del estadístico de contraste anterior para nuestra muestra. El p-valor del contraste vale:
$$
p=P(\chi_{k-1}^2 > \chi_0),
$$

## Contraste $\chi^2$ de Pearson

con el significado usual: 

* si $p<0.05$, concluimos que tenemos evidencias suficientes para rechazar la hipótesis nula los datos no siguen esa distribución con esos parámetros,
* si $p>0.1$, concluimos que no tenemos evidencias suficientes para rechazar que la muestra siga esa distribución con esos parámetros y,
* si $0.05\leq p\leq 0.1$, estamos en la zona de penumbra. Necesitamos más datos para tomar una decisión clara.


## Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado**

Imaginemos que queremos ver si un dado está trucado o no.

Si no está trucado, cuando tiramos el dado y miramos el resultado $X$, cada resultado $i=1,\ldots,6$ tiene probabilidad $P(X=i)=\frac{1}{6}$. Ésta sería, por tanto, la función de distribución de la variable $X_k$.

Las clases serían posibles valores que puede tener el dado al lanzarse. La distribución de la variable $X_k$ sería en este caso:

<div class="center">
| $X_k$ | $1$    | $2$ | $3$ | $4$ | $5$ | $6$ | Total |
|:----|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| $P(X_k=i)$   | $\frac{1}{6}$ |$\frac{1}{6}$ |$\frac{1}{6}$ |$\frac{1}{6}$ |$\frac{1}{6}$ |$\frac{1}{6}$ |  $1$
</div>
</div>

## Ejemplo
<div class="example">

Nos dicen que han lanzado el dado  120 veces y se han obtenido los resultados siguientes:

<div class="center">
| Clases | Clase 1    | Clase 2 | Clase 3 |Clase 4 |Clase 5 |Clase 6 | Total |
|:----|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Frecuencias empíricas   | 20 | 22 | 17 | 18 | 19 | 24 | `r 20+22+17+18+19+24`
</div>

¿Hay bastante evidencia que el dado esté trucado?
</div>

<div class="example-sol">
**Resolución**

La tabla de **frecuencias teóricas** sería:

<div class="center">
| Clases | Clase 1    | Clase 2 | Clase 3 |Clase 4 |Clase 5 |Clase 6 | Total |
|:----|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Frecuencias teóricas  | $\frac{120}{6}=20$ | $\frac{120}{6}=20$ |$\frac{120}{6}=20$ |$\frac{120}{6}=20$ |$\frac{120}{6}=20$ |$\frac{120}{6}=20$ | $120$
</div>

</div>


## Ejemplo

<div class="example-sol">
El valor del estadístico $\chi^2$ sería:
$$
\chi_0 = \frac{(20-20)^2}{20}+\frac{(22-20)^2}{20}+\frac{(17-20)^2}{20}+\frac{(18-20)^2}{20}+\frac{(19-20)^2}{20}+\frac{(24-20)^2}{20} = `r round((22-20)^2/20+(17-20)^2/20+(18-20)^2/20+(19-20)^2/20+(24-20)^2/20,4)`.
$$


El p-valor del contraste sería $P(\chi_5^2 > `r round((22-20)^2/20+(17-20)^2/20+(18-20)^2/20+(19-20)^2/20+(24-20)^2/20,4)`)$:
```{r}
pchisq((22-20)^2/20+(17-20)^2/20+(18-20)^2/20+(19-20)^2/20+(24-20)^2/20,5,
       lower.tail=FALSE)
```

Como el p-valor es grande, concluimos que no tenemos evidencias suficientes para rechazar que el dado esté trucado.

</div>

## Condiciones para poder aplicar el test $\chi^2$ de Pearson

El test de **bondad de ajuste** está basado en el **estadístico $\chi^2$** que recordemos sigue aproximadamente una distribución $\chi^2_{k-1}$ grados de libertad.

Al estar basado en un **Teorema Límite**, para que dicha aproximación sea efectiva, las condiciones siguientes se tienen que verificar:

* el tamaño de la muestra tiene que ser grande: $n\geq 25$ o mejor $n\geq 30$,

* las clases tienen que cubrir todos los resultados posibles, (a la práctica: $n=\sum_{i=1}^k n_i = \sum_{i=1}^k e_i$)

* las **frecuencias teóricas** tienen que ser mayores o iguales que 5: $e_i\geq 5$, para todo $i=1,\ldots,k$.

## Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado**

En el ejemplo del lanzamiento del dado, observamos que se verifican las condiciones anteriores:

* $n=120\geq 30$,
* $\sum_{i=1}^6 n_i = 20+22+17+18+19+24=120=\sum_{i=1}^6 e_i =20+20+20+20+20+20$,
* $e_1=e_2=e_3=e_4=e_5=e_6=20\geq 5.$

</div>

## Resolución de un test $\chi^2$ de Pearson en `R`
Para resolver un **contraste de bondad de ajuste** en `R`, hemos de usar la función `chisq.test`.

Su sintaxis básica es
```{r,eval=FALSE}
chisq.test(x, p=..., rescale.p=..., simulate.p.value=...)
```
donde:

* `x` es el vector (o la tabla, calculada con `table`) de frecuencias **absolutas observadas** de las clases en la muestra, recordemos que las hemos llamado $n_i$, $i=1,\ldots, k$.

## Resolución de un test $\chi^2$ de Pearson en `R`

* `p` es el vector de probabilidades teóricas de las clases para la distribución que queremos contrastar. O sea, es el vector de la función de probabilidad de la variable $X_k$: $p_i=P(X_k=i)$, $i=1,\ldots k$. 

Si no lo especificamos, se entiende que la probabilidad es la misma para todas las clases. Obviamente, estas probabilidades se tienen que especificar en el mismo orden que las frecuencias de `x` y, como son las probabilidades de todos los resultados posibles, en principio tienen que sumar 1; esta condición se puede relajar con el siguiente parámetro.


## Resolución de un test $\chi^2$ de Pearson en `R`
* `rescale.p` es un parámetro lógico que, si se iguala a `TRUE`, indica que  los valores de `p` no son probabilidades, sino solo proporcionales a las probabilidades; esto hace que `R` tome como probabilidades teóricas los valores de `p`  partidos por su suma, para que sumen 1.  

Por defecto vale `FALSE`, es decir, se supone que el vector que se entra como  `p`  son probabilidades y por lo tanto debe sumar 1, y si esto no pasa se genera un mensaje de error indicándolo. Igualarlo a `TRUE` puede ser útil, porque nos permite especificar las probabilidades mediante  las frecuencias esperadas o mediante porcentajes. Pero también es peligroso, porque si nos hemos equivocado y hemos entrado un vector en `p` que no corresponda a una probabilidad, `R` no nos avisará.


## Resolución de un test $\chi^2$ de Pearson en `R`

*  `simulate.p.value` es un  parámetro lógico que indica a la función si debe
optar por una simulación para el cálculo  del p-valor del contraste. 

Por defecto vale `FALSE`, en cuyo caso este p-valor no se simula sino que se calcula mediante la distribución $\chi^2$ correspondiente.  

Si falla una o más condiciones para que se aplique el **test de bondad de ajuste**, tendremos que especificarlo como `TRUE` y `R` realizará una serie  de replicaciones aleatorias de la situación teórica: por defecto, 2000, pero su número se puede especificar mediante el parámetro `B`. Es decir,  generará un conjunto de vectores aleatorios de frecuencias con la distribución que queremos contrastar,  cada uno de suma total la de `x`.  A continuación, calculará la proporción de estas repeticiones en las que el estadístico de contraste es  mayor o igual que el obtenido para `x`, y éste será el  p-valor que dará. 

## Ejemplo
<div class="example">
**Ejemplo de la tabla de datos `iris`**

Consideremos la tabla de datos `iris`. Imaginemos que queremos ver si en una muestra de tamaño 10, hay la misma cantidad de flores de las tres especies: setosa, versicolor y virgínica.
</div>


<div class="example-sol">
En primer lugar, elegimos una muestra de 10 flores:
```{r}
set.seed(2020)  # fijamos la semilla de aleatorización
muestra.flores = sample(iris$Species,10)
```

</div>

## Ejemplo

<div class="example-sol">
A continuación, realizamos el contraste de bondad de ajuste:
```{r}
chisq.test(table(muestra.flores))
```
Fijaos que `R` nos avisa que las aproximaciones pueden ser incorrectas. La razón es que las **frecuencias observadas** no son mayores que 5 ya que éstas valen: $e_{setosa}=e_{versicolor}=e_{virginica}=\frac{10}{3}\approx `r round(10/3,3)`.$
</div>

## Ejemplo

<div class="example-sol">
Para solventar este problema, vamos a simular el p-valor:
```{r}
chisq.test(table(muestra.flores), simulate.p.value = TRUE, B=2000)
```
Vemos que con 2000 replicaciones, al obtener un p-valor grande, podemos concluir que no tenemos evidencias suficientes para rechazar que la proporción de especies en la muestra no sea la misma.
</div>

## Ejemplo de normalidad
<div class="example">
**Ejemplo para comprobar si cierta distribución es normal usando el test $\chi^2$ de Pearson en `R`**

Un técnico de medio ambiente quiere estudiar el aumento de temperatura del agua
a dos kilómetros de los vertidos de agua autorizados de una
planta industrial.


El responsable de la empresa afirma que *estos aumentos de temperatura siguen una ley normal
con $\mu=3.5$ décimas de grado C y $\sigma=0.7$ décimas de grado C.*


El técnico pone  esta afrimación en entredicho. Para decidirlo, toma una muestra aleatoria de 40 observaciones del aumento
de las temperaturas (en décimas de grado) y se obtienen los resultados siguientes:
</div>

## Ejemplo de normalidad
<div class="example">
<div class="center">
|Rango de temperaturas | Frecuencias|
|:----|----:|
|1.45-1.95 | 2 |
|1.95-2.45 | 1 |
|2.45-2.95 | 4 |
|2.95-3.45 | 15 |
|3.45-3.95 | 10 |
|3.95-4.45 | 5 |
|4.45-4.95 | 3 |
</div>
</div>

## Ejemplo de normalidad
<div class="example">
¿Hay evidencia que la sospecha del técnico sea verdadera?
</div>

<div class="example-sol">
El contraste a realizar es el siguiente:
$$\left\{
\begin{array}{l}
H_0:\mbox{La distribución de los aumentos de temperatura es $N(3.5,0.7)$,}\\[1ex]
H_1: \mbox{La distribución de los aumentos de temperatura no es $N(3.5,0.7)$.}
\end{array}
\right.$$

Para poder aplicar el **test $\chi^2$ de Pearson**, como la distribución teórica es normal y su dominio es todo $\mathbb{R}$, tendremos que ampliar los intervalos de la tabla anterior para asegurarnos que los valores de la tabla pueden alcanzar todos los valores de la distribución teórica:
</div>

## Ejemplo de normalidad
<div class="example-sol">
<div class="center">
|Rango de temperaturas | Frecuencias|
|:----|----:|
|$(-\infty,1.95]$ | 2 |
|$(1.95,2.45]$ | 1 |
|$(2.45,2.95]$ | 4 |
|$(2.95,3.45]$ | 15 |
|$(3.45,3.95]$ | 10 |
|$(3.95,4.45]$ | 5 |
|$(4.45,\infty)$ | 3 |
</div>

</div>

## Ejemplo de normalidad
<div class="example-sol">


La tabla anterior nos determina las clases a considerar que corresponderían a los intervalos. Las frecuencias empíricas serían las que nos da la segunda columna de la tabla.

A continuación, vamos a calcular las frecuencias teóricas. Para ello, en primer lugar, hay que hallar la función de probabilidad de la variable $X_k$:

* Cálculo de $p_1 = P(X_0\in \mbox{Clase }1)$:
$$
p_1  = P(X_0\leq 1.95)=P\left(Z\leq \frac{1.95-3.5}{0.7}\right)=P(Z\leq `r round((1.95-3.5)/0.7,3)`)=`r round(pnorm(1.95,3.5,0.7),3)`,
$$
donde $Z=N(0,1)$. Por tanto, $e_1 = n\cdot `r round(pnorm(1.95,3.5,0.7),3)`=40\cdot `r round(pnorm(1.95,3.5,0.7),3)`=`r round(40*pnorm(1.95,3.5,0.7),2)`.$

* Cálculo de $p_2 = P(X_0\in \mbox{Clase }2)$:
$$
\begin{array}{rl}
p_2 & = P(1.95 < X_0\leq 2.45)=P\left(\frac{1.95-3.5}{0.7} < Z \leq  \frac{2.45-3.5}{0.7}\right) =P(`r round((1.95-3.5)/0.7,3)` < Z\leq `r round((2.45-3.5)/0.7,3)`) \\ & =P(Z\leq `r round((2.45-3.5)/0.7,3)`)-P(Z\leq `r round((1.95-3.5)/0.7,3)`)=`r round(pnorm(2.45,3.5,0.7),3)`-`r round(pnorm(1.95,3.5,0.7),3)`=`r round(pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7),3)`.
\end{array}
$$
Por tanto, $e_2 = n\cdot `r round(pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7),3)`=40\cdot `r round(pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7),3)`=`r round(40*(pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7)),2)`.$
</div>

## Ejemplo de normalidad
<div class="example-sol">


* Cálculo de $p_3 = P(X_0\in \mbox{Clase }3)$:
$$
\begin{array}{rl}
p_3 & = P(2.45 < X_0\leq 2.95)=P\left(\frac{2.45-3.5}{0.7} < Z \leq  \frac{2.95-3.5}{0.7}\right) =P(`r round((2.45-3.5)/0.7,3)` < Z\leq `r round((2.95-3.5)/0.7,3)`) \\ & =P(Z\leq `r round((2.95-3.5)/0.7,3)`)-P(Z\leq `r round((2.45-3.5)/0.7,3)`)=`r round(pnorm(2.95,3.5,0.7),3)`-`r round(pnorm(2.45,3.5,0.7),3)`=`r round(pnorm(2.95,3.5,0.7)-pnorm(2.45,3.5,0.7),3)`.
\end{array}
$$
Por tanto, $e_3 = n\cdot `r round(pnorm(2.95,3.5,0.7)-pnorm(2.45,3.5,0.7),3)`=40\cdot `r round(pnorm(2.95,3.5,0.7)-pnorm(2.45,3.5,0.7),3)`=`r round(40*(pnorm(2.95,3.5,0.7)-pnorm(2.45,3.5,0.7)),2)`.$

* Cálculo de $p_4 = P(X_0\in \mbox{Clase }4)$:
$$
\begin{array}{rl}
p_4 & = P(2.95 < X_0\leq 3.45)=P\left(\frac{2.95-3.5}{0.7} < Z \leq  \frac{3.45-3.5}{0.7}\right) =P(`r round((2.95-3.5)/0.7,3)` < Z\leq `r round((3.45-3.5)/0.7,3)`) \\ & =P(Z\leq `r round((3.45-3.5)/0.7,3)`)-P(Z\leq `r round((2.95-3.5)/0.7,3)`)=`r round(pnorm(3.45,3.5,0.7),3)`-`r round(pnorm(2.95,3.5,0.7),3)`=`r round(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7),3)`.
\end{array}
$$
Por tanto, $e_4 = n\cdot `r round(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7),3)`=40\cdot `r round(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7),3)`=`r round(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)),2)`.$

* Cálculo de $p_5 = P(X_0\in \mbox{Clase }5)$:
$$
\begin{array}{rl}
p_5 & = P(3.45 < X_0\leq 3.95)=P\left(\frac{3.45-3.5}{0.7} < Z \leq  \frac{3.95-3.5}{0.7}\right) =P(`r round((3.45-3.5)/0.7,3)` < Z\leq `r round((3.95-3.5)/0.7,3)`) \\ & =P(Z\leq `r round((3.95-3.5)/0.7,3)`)-P(Z\leq `r round((3.45-3.5)/0.7,3)`)=`r round(pnorm(3.95,3.5,0.7),3)`-`r round(pnorm(3.45,3.5,0.7),3)`=`r round(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7),3)`.
\end{array}
$$
Por tanto, $e_5 = n\cdot `r round(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7),3)`=40\cdot `r round(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7),3)`=`r round(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)),2)`.$

</div>


## Ejemplo de normalidad
<div class="example-sol">

* Cálculo de $p_6 = P(X_0\in \mbox{Clase }6)$:
$$
\begin{array}{rl}
p_6 & = P(3.95 < X_0\leq 4.45)=P\left(\frac{3.95-3.5}{0.7} < Z \leq  \frac{4.45-3.5}{0.7}\right) =P(`r round((3.95-3.5)/0.7,3)` < Z\leq `r round((4.45-3.5)/0.7,3)`) \\ & =P(Z\leq `r round((4.45-3.5)/0.7,3)`)-P(Z\leq `r round((3.95-3.5)/0.7,3)`)=`r round(pnorm(4.45,3.5,0.7),3)`-`r round(pnorm(3.95,3.5,0.7),3)`=`r round(pnorm(4.45,3.5,0.7)-pnorm(3.95,3.5,0.7),3)`.
\end{array}
$$
Por tanto, $e_6 = n\cdot `r round(pnorm(4.45,3.5,0.7)-pnorm(3.95,3.5,0.7),3)`=40\cdot `r round(pnorm(4.45,3.5,0.7)-pnorm(3.95,3.5,0.7),3)`=`r round(40*(pnorm(4.45,3.5,0.7)-pnorm(3.95,3.5,0.7)),2)`.$

* Cálculo de $p_7 = P(X_0\in \mbox{Clase }7)$:
$$
p_1  = P(X_0\geq 4.45)=P\left(Z\geq \frac{4.45-3.5}{0.7}\right)=P(Z\geq `r round((4.45-3.5)/0.7,3)`)=`r round(pnorm(4.45,3.5,0.7,lower.tail=FALSE),3)`,
$$
donde $Z=N(0,1)$. Por tanto, $e_1 = n\cdot `r round(pnorm(4.45,3.5,0.7,lower.tail=FALSE),3)`=40\cdot `r round(pnorm(4.45,3.5,0.7,lower.tail=FALSE),3)`=`r round(40*pnorm(4.45,3.5,0.7,lower.tail=FALSE),2)`.$

Observamos que las **frecuencias teóricas** $e_1$, $e_2$ y $e_7$ son menores que 5. Por tanto, no se cumplen las condiciones para poder aplicar el **contraste de bondad de ajuste**. 

</div>

## Ejemplo de normalidad
<div class="example-sol">

Para solventar este problema, agruparemos los intervalos $(-\infty,1.95]$, $(1.95,2.45]$, $(2.45,2.95]$ en el intervalo $(-\infty, 2.95)$ y los intervalos $(3.95,4.45]$ y $(4.45,\infty)$ en el intervalo $(3.95,\infty)$. De esta forma, la tabla de frecuencias empíricas quedará de la forma siguiente:

<div class="center">
|Rango de temperaturas | Frecuencias|
|:----|----:|
|$(-\infty,2.95]$ | $2+1+4=`r 2+1+4`$ |
|$(2.95,3.45]$ | $15$ |
|$(3.45,3.95]$ | $10$ |
|$(3.95,\infty]$ | $5+3=`r 5+3`$  |
</div>


</div>

## Ejemplo de normalidad
<div class="example-sol">
Las **frecuencias teóricas** de la nueva tabla serán las siguientes:

* $e_1 = `r round(40*pnorm(1.95,3.5,0.7),2)`+`r round(40*(pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7)),2)`+`r round(40*(pnorm(2.95,3.5,0.7)-pnorm(2.45,3.5,0.7)),2)` =`r round(40*pnorm(2.95,3.5,0.7),2)`$.
* $e_2 = n\cdot `r round(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7),3)`=40\cdot `r round(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7),3)`=`r round(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)),2)`.$
* $e_3 =  n\cdot `r round(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7),3)`=40\cdot `r round(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7),3)`=`r round(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)),2)`.$
* $e_4 = `r round(40*(pnorm(4.45,3.5,0.7)-pnorm(3.95,3.5,0.7)),2)`+`r round(40*pnorm(4.45,3.5,0.7,lower.tail=FALSE),2)`= `r round(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE),2)`.$

Ahora vemos que las **frecuencias teóricas** son mayores o iguales que 5 y, por tanto, se verifican las condiciones para poder aplicar el **test de bondad de ajuste**.
</div>

## Ejemplo de normalidad
<div class="example-sol">
La tabla siguiente resume los cálculos realizados:

<div class="center">
|Rango de temperaturas | Frecuencias empíricas| Frecuencias teóricas |
|:----|----:|----:|
|$(-\infty,2.95]$ | $`r 2+1+4`$ | $`r round(40*pnorm(2.95,3.5,0.7),2)`$|
|$(2.95,3.45]$ | $15$ | $`r round(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)),2)`$|
|$(3.45,3.95]$ | $10$ | $`r round(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)),2)`$|
|$(3.95,\infty]$ | $`r 5+3`$  | $`r round(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE),2)`$
</div>
</div>

## Ejemplo de normalidad
<div class="example-sol">
El valor del **estadístico de contraste** $\chi^2$ vale:
$$
\chi_0 = \frac{(7-`r round(40*pnorm(2.95,3.5,0.7),2)`)^2}{`r round(40*pnorm(2.95,3.5,0.7),2)`}+ \frac{(15-`r round(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)),2)`)^2}{`r round(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)),2)`}+ \frac{(10-`r round(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)),2)`)^2}{`r round(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)),2)`}+\frac{(8-`r round(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE),2)`)^2}{`r round(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE),2)`}=`r round((7-40*pnorm(2.95,3.5,0.7))^2/(40*pnorm(2.95,3.5,0.7))+(15-40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))^2/(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))+(10-40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))^2/(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))+(8-40*pnorm(3.95,3.5,0.7,lower.tail=FALSE))^2/(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE)),3)`.
$$
El p-valor del contraste será:
$$
p=P(\chi_{3} > `r round((7-40*pnorm(2.95,3.5,0.7))^2/(40*pnorm(2.95,3.5,0.7))+(15-40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))^2/(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))+(10-40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))^2/(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))+(8-40*pnorm(3.95,3.5,0.7,lower.tail=FALSE))^2/(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE)),3)`)=`r round(pchisq((7-40*pnorm(2.95,3.5,0.7))^2/(40*pnorm(2.95,3.5,0.7))+(15-40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))^2/(40*(pnorm(3.45,3.5,0.7)-pnorm(2.95,3.5,0.7)))+(10-40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))^2/(40*(pnorm(3.95,3.5,0.7)-pnorm(3.45,3.5,0.7)))+(8-40*pnorm(3.95,3.5,0.7,lower.tail=FALSE))^2/(40*pnorm(3.95,3.5,0.7,lower.tail=FALSE)),3,lower.tail=FALSE),3)`.
$$
Como el p-valor es grande, concluimos que no tenemos evidencias suficientes para rechazar que el aumento de temperatura no siga una distribución normal de parámetros $\mu =3.5$ décimas de grado y $\sigma =0.7$ décimas de grado.
</div>


## Ejemplo de normalidad con `R`
<div class="example">
Vamos a realizar el ejemplo anterior usando `R`.

En primer lugar, definimos las clases definiendo los extremos de los intervalos y las **frecuencias empíricas**:
```{r}
extremos.izquierdos = c(-Inf,1.95,2.45,2.95,3.45,3.95,4.45)
extremos.derechos = c(1.95,2.45,2.95,3.45,3.95,4.45,Inf)
frecuencias.empíricas = c(2,1,4,15,10,5,3)
n=sum(frecuencias.empíricas)
```

Para hallar las **frecuencias teóricas** usamos la función `pnorm` de `R`:
```{r}
mu=3.5; sigma=0.7;
probabilidades.teóricas = pnorm(extremos.derechos,mu,sigma)-
  pnorm(extremos.izquierdos,mu,sigma)
frecuencias.teóricas = n*probabilidades.teóricas
round(frecuencias.teóricas,2)
```

</div>

## Ejemplo de normalidad con `R`
<div class="example">
Por último, aplicamos el test de la $\chi^2$ usando la función `chisq.test`:
```{r}
chisq.test(frecuencias.empíricas,p=probabilidades.teóricas)
```
`R` nos avisa que la aproximación $\chi^2$ puede no ser correcta. Nosotros sabemos la razón: hay tres probabilidades teóricas que son menores que 5.

Llegados a este punto, podemos actuar de dos formas: juntamos intervalos o simulamos el p-valor.

</div>

## Ejemplo de normalidad con `R`
<div class="example">
Si optamos por la primera opción, tendremos que hacer:
```{r}
extremos.izquierdos2=extremos.izquierdos[c(1,4,5,6)]
extremos.derechos2 = extremos.derechos[c(3,4,5,7)]
frecuencias.empíricas2 = c(sum(frecuencias.empíricas[1:3]),
                           frecuencias.empíricas[4:5],sum(frecuencias.empíricas[6:7]))
probabilidades.teóricas2 =pnorm(extremos.derechos2,mu,sigma)-
  pnorm(extremos.izquierdos2,mu,sigma)
frecuencias.teóricas2 = n*probabilidades.teóricas2
chisq.test(frecuencias.empíricas2,p=probabilidades.teóricas2)
```
Vemos que obtenemos los mismos valores que los cálculos realizados a mano.

</div>

## Ejemplo de normalidad con `R`
<div class="example">
Si optamos por la segunda opción, hemos de hacer:

```{r}
chisq.test(frecuencias.empíricas,p=probabilidades.teóricas,simulate.p.value = TRUE,
           B=2000)
```
Aunque obtengamos un p-valor distinto, llegamos a la misma conclusión anterior.

</div>

## Test $\chi^2$ de Pearson con parámetros poblacionales desconocidos

El ejemplo visto anteriormente de normalidad no es realista en el sentido que la mayoría de las veces desconoceremos la media $\mu$ y la desviación típica $\sigma$ de la variable de la población $X_0$ a la que se refiere la hipótesis nula $H_0$.

Cuando la variable $X_0$ de la población de contraste dependa de algún(os) parámetro(s) desconocido(s), necesitamos conocer su valor de cara a calcular las **frecuencias esperadas** o **frecuencias teóricas** $e_i$.

## Test $\chi^2$ de Pearson con parámetros poblacionales desconocidos

La manera de resolver este inconveniente, es estimar dichos parámetros usando el **estimador máximo verosímil** correspondiente.

Una vez estimados el(los) parámetro(s) del(de los) que depende la variable de la población $X_0$, podemos realizar el **test de bondad de ajuste** tal como hemos visto pero ahora los grados de libertad de la distribución $\chi^2$ disminuyen. En concreto, valen: $k-1-\mbox{número de parámetros estimados.}$

## Ejemplo
<div class="example">
**Ejemplo**

Se quiere determinar si el número de veces que aparece la secuencia GATACA en una
cadena de ADN de longitud 1000 sigue una ley Poisson.

Se toman varias  muestras de cadenas de ADN de longitud 1000 y se  cuentan los números de GATACA

<div class="center">
|número $x_i$ de veces que aparece GATACA| 0 | 1 | 2 | 3 | 4 | 5|
|:------|--:|--:|--:|--:|--:|--:|
|frecuencia empírica $n_i$ | 229 | 211 | 93 | 35 | 7 | 1 |
</div>

Hemos realizado en total $n=229 + 211+ 93+ 35 + 7 + 1=576$ observaciones.
</div>

## Ejemplo
<div class="example-sol">
El contraste a realizar es el siguiente:
$$
\left\{ \begin {array}{ll}
H_0: \mbox{La muestra proviene de una distribución } Po(\lambda),\\
H_1: \mbox{La muestra no proviene de esta distribución.}
\end{array}
\right.$$

Al no conocer el parámetro $\lambda$, hemos de estimarlo.

Recordemos que el **estimador máximo verosímil** del parámetro $\lambda$ de una distribución de Poisson es su **media muestral**: $\hat{\lambda}=\overline{X}$:
$$
\hat{\lambda}  =\dfrac{229\cdot 0+ 211\cdot 1+  93\cdot 2+ 35\cdot 3+7\cdot 4+ 1\cdot 5}{229+ 211+ 93 +35 + 7 + 1}
  =\dfrac{`r 211+93*2+35*3+7*4+1*5`}{`r 229+ 211+ 93 +35 + 7 + 1`}=`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`.
$$

Las clases deben cubrir todo el conjunto de valores de la variable $X_0$ que, en nuestro caso, al ser una variable de Poisson, serían todos los enteros positivos: $D_{X_0}=\{0,1,\ldots\}$.

Usando la tabla de **frecuencias empíricas**, consideramos las clases siguientes:
$$
\mbox{Clase 0}:{X_0=0},\ \mbox{Clase 1}:{X_0=1},\ \mbox{Clase 2}:{X_0=2},\ \mbox{Clase 3}:{X_0=3},\ \mbox{Clase 4}:{X_0=4},\ \mbox{Clase 5}:{X_0\geq 5}.
$$
</div>


## Ejemplo
<div class="example-sol">
Recordemos que la función de probabilidad de una variable de Poisson de parámetro $\lambda$ vale: $P(X_0=i)=\frac{\lambda^i}{i!}\mathrm{e}^{-\lambda}$, donde $i\in D_{X_0}$.

Las **frecuencias esperadas o teóricas** $e_i$ se calculan de la forma siguiente:

* $e_0 = n\cdot P(X_0\in \mbox{Clase }0)=n\cdot P(X_0 =0)=`r 229+ 211+ 93 +35 + 7 + 1`\cdot \frac{`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`^0}{0!}\mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=
 `r 229+ 211+ 93 +35 + 7 + 1`\cdot \mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=`r round((229+ 211+ 93 +35 + 7 + 1)*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1)),2)`.$
 
* $e_1 = n\cdot P(X_0\in \mbox{Clase }1)=n\cdot P(X_0 =1)=`r 229+ 211+ 93 +35 + 7 + 1`\cdot \frac{`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`^1}{1!}\mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=`r round((229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1)),2)`.$

* $e_2 = n\cdot P(X_0\in \mbox{Clase }2)=n\cdot P(X_0 =2)=`r 229+ 211+ 93 +35 + 7 + 1`\cdot \frac{`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`^2}{2!}\mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=`r round((229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^2*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(2),2)`.$

* $e_3 = n\cdot P(X_0\in \mbox{Clase }3)=n\cdot P(X_0 =3)=`r 229+ 211+ 93 +35 + 7 + 1`\cdot \frac{`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`^3}{3!}\mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=`r round((229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^3*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(3),2)`.$

* $e_4 = n\cdot P(X_0\in \mbox{Clase }4)=n\cdot P(X_0 =4)=`r 229+ 211+ 93 +35 + 7 + 1`\cdot \frac{`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`^4}{4!}\mathrm{e}^{-`r round((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1),3)`}=`r round((229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^4*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(4),2)`.$
</div>

## Ejemplo
<div class="example-sol">
* El cálculo de $e_5$ se realiza de forma ligeramente diferente de los demás:
```{r,echo=FALSE}
n=229+ 211+ 93 +35 + 7 + 1;
e0=(229+ 211+ 93 +35 + 7 + 1)*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1));
e1=(229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1));
e2=(229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^2*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(2);
e3=(229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^3*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(3);
e4=(229+ 211+ 93 +35 + 7 + 1)*((211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))^4*exp(-(211+93*2+35*3+7*4+1*5)/(229+ 211+ 93 +35 + 7 + 1))/factorial(4);
```

$$
\begin{array}{rl}
e_5 & = n\cdot P(X_0\in \mbox{Clase }5)=n\cdot P(X_0 \geq 5)= n\cdot (1-P(X_0\leq 4)) \\
& =n\cdot (1-(P(X_0=0)+P(X_0=1)+P(X_0=2)+P(X_0=3)+P(X_0=4)))\\
& = `r n`-(`r round(e0,2)`+
`r round(e1,2)`+`r round(e2,2)`+`r round(e3,2)`+`r round(e4,2)`
)=`r round(n-(e0+e1+e2+e3+e4),2)`.
\end{array}
$$
Como la clase 5 no verifica las condiciones de aplicación del **contraste de bondad de ajuste** al tener una **frecuencia esperada** menor que 5, juntaremos las dos últimas clases y las nuevas clases serán:

$$
\mbox{Clase 0}:{X_0=0},\ \mbox{Clase 1}:{X_0=1},\ \mbox{Clase 2}:{X_0=2},\ \mbox{Clase 3}:{X_0=3},\ \mbox{Clase 4}:{X_0\geq4}.
$$
Las **frecuencias esperadas** de las nuevas clases serán:

* $e_0 = n\cdot P(X_0\in \mbox{Clase }0)=n\cdot P(X_0 =0)=`r round(e0,2)`.$
* $e_1 = n\cdot P(X_0\in \mbox{Clase }1)=n\cdot P(X_0 =1)=`r round(e1,2)`.$
* $e_2 = n\cdot P(X_0\in \mbox{Clase }2)=n\cdot P(X_0 =2)=`r round(e2,2)`.$
* $e_3 = n\cdot P(X_0\in \mbox{Clase }3)=n\cdot P(X_0 =3)=`r round(e3,2)`.$
</div>

## Ejemplo
<div class="example-sol">
* El cálculo de $e_4$ se realiza de forma parecida al cálculo de la clase 5 anterior:
$$
\begin{array}{rl}
e_4 & = n\cdot P(X_0\in \mbox{Clase }4)=n\cdot P(X_0 \geq 4)= n\cdot (1-P(X_0\leq 3)) \\
& =n\cdot (1-(P(X_0=0)+P(X_0=1)+P(X_0=2)+P(X_0=3))\\
& = `r n`-(`r round(e0,2)`+
`r round(e1,2)`+`r round(e2,2)`+`r round(e3,2)`
)=`r round(n-(e0+e1+e2+e3),2)`.
\end{array}
$$

```{r, echo=FALSE}
e4n=n-(e0+e1+e2+e3);
```

</div>

## Ejemplo
<div class="example-sol">
Resumamos en una tabla las **frecuencias empíricas** y las **frecuencias esperadas**:

<div class="center">
|Clase | Frecuencias empíricas| Frecuencias teóricas |
|:----|----:|----:|
|$\{X_0=0\}$ | $229$ | $`r round(e0,2)`$|
|$\{X_0=1\}$ | $211$ | $`r round(e1,2)`$|
|$\{X_0=2\}$ | $93$ | $`r round(e2,2)`$|
|$\{X_0 = 3\}$ | $35$  | $`r round(e3,2)`$|
|$\{X_0\geq 4\}$ | $7+1=8$ | $`r round(e4n,2)`$|
</div>
</div>

## Ejemplo
<div class="example-sol">
El valor del **estadístico de contraste** será:
$$
\chi_0 = \frac{(229-`r round(e0,2)`)^2}{`r round(e0,2)`}+\frac{(211-`r round(e1,2)`)^2}{`r round(e1,2)`}+\frac{(93-`r round(e2,2)`)^2}{`r round(e2,2)`}+\frac{(35-`r round(e3,2)`)^2}{`r round(e3,2)`}+\frac{(8-`r round(e4n,2)`)^2}{`r round(e4n,2)`} =`r round((229-e0)^2/e0+(211-e1)^2/e1+(93-e2)^2/e2+(35-e3)^2/e3+(8-e4n)^2/e4n,3)`.
$$

Antes de calcular el p-valor del contraste, calculemos los grados de libertad de la variable $\chi^2$. Éstos serán: $g.l.=5-1-1=3$ ya que hemos estimado un parámetro, $\lambda$.

El p-valor del contraste será:
$$
p=P(\chi^2_3 > `r round((229-e0)^2/e0+(211-e1)^2/e1+(93-e2)^2/e2+(35-e3)^2/e3+(8-e4n)^2/e4n,3)`)=`r round(pchisq((229-e0)^2/e0+(211-e1)^2/e1+(93-e2)^2/e2+(35-e3)^2/e3+(8-e4n)^2/e4n,3,lower.tail=FALSE),3)`.
$$
Como el p-valor es muy grande, concluimos que no tenemos evidencias suficientes para rechazar que el número de veces que aparece la secuencia GATACA en una cadena ADN de longitud 1000 sigue una ley de Poisson.
</div>

## Ejemplo con `R`
<div class="example-sol">
Resolvamos el ejemplo anterior con ayuda de `R`. 

En primer lugar, definimos las **frecuencias empíricas** y las **probabilidades esperadas y teóricas**:
```{r}
frecuencias.empíricas = c(229,211,93,35,8);
estimación.lambda = (211+93*2+35*3+7*4+1*5)/(229+211+93+35+7+1);
probabilidades.esperadas = c(dpois(0,estimación.lambda),dpois(1,estimación.lambda),
                             dpois(2,estimación.lambda),dpois(3,estimación.lambda),
                             1-ppois(3,estimación.lambda));
```
</div>

## Ejemplo con `R`
<div class="example-sol">
A continuación, realizamos el **test de bondad de ajuste** usando la función `chisq.test`:
```{r}
chisq.test(frecuencias.empíricas,p=probabilidades.esperadas)
```
Nos fijamos que el valor del **estadístico de contraste** coincide con el valor obtenido haciendo los cálculos a mano. Sin embargo, el p-valor no coincide. La razón es que `R` no tiene forma de saber si hemos estimado algún parámetro o no. Por este motivo, considera que los grados de libertad del **estadístico de contraste** son 4 en lugar de 3. 
</div>


## Ejemplo con `R`
<div class="example-sol">
Entonces para hallar el p-valor correcto, hemos de usar la función `pchisq`:
```{r}
test.chi2=chisq.test(frecuencias.empíricas,p=probabilidades.esperadas)
pchisq(test.chi2[[1]],3,lower.tail=FALSE)
```
Comprobamos que ahora sí tenemos el p-valor correcto.
</div>

# Contrastes donde la variable $X_0$ es continua

## Introducción
En esta sección, vamos a ver contrastes específicos para comprobar si una variable sigue una determinada distribución continua.

El **test de bondad de ajuste** se puede aplicar en estos casos pero exige que el tamaño de la muestra $n$ tiene que ser grande por dos razones: en primer lugar, $n$ debe ser mayor que 30 y en segundo lugar, las **frecuencias esperadas** deben ser mayores que 5, condición que raramente se consigue para valores de $n$ pequeños.

## Test de Kolmogorov-Smirnov (K-S test)

El **test de Kolgomorov-Smirnov** (**K-S**) es un test genérico para contrastar la bondad de ajuste a distribuciones continuas.  

Se puede usar con muestras pequeñas (se suele recomendar 5 elementos como el tamaño mínimo para que el resultado sea significativo), pero  la muestra no puede contener valores repetidos: si los contiene, la distribución del estadístico de contraste bajo la hipótesis nula no es la que predice la teoría sino que solo se aproxima a ella, y por lo tanto los p-valores que se obtienen son aproximados. 

El test K-S realiza un contraste en el que la hipótesis nula es que la muestra proviene de una distribución continua  completamente especificada. Es decir, no sirve por ejemplo para contrastar si la muestra proviene de "alguna" distribución normal, sino solo para contrastar si proviene de una distribución normal con una media y una desviación típica concretas. 

## Test de Kolmogorov-Smirnov (K-S test)

Por tanto, si queremos contrastar que la muestra proviene de alguna distribución de una familia concreta y  estimamos sus parámetros a partir de la muestra, el test K-S solo nos permite rechazar o no la hipótesis de que la muestra proviene de la distribución de esa familia con exactamente esos parámetros.

Si el resultado es rechazar la hipótesis nula, significa que tenemos indicios suficientes para rechazar que la muestra proviene de la distribución de la familia con los parámetros que hemos especificado pero podría ser que la muestra siguiese una distribución de la misma familia con otros parámetros.

## Test de Kolmogorov-Smirnov (K-S test)
Sean $x_1,x_2,\ldots,x_n$, con todos los valores diferentes tal como hemos comentado, y queremos contrastar si ha sido producida por una variable $X$ con distribución $F_X$.

Para aplicar el test **K-S** seguimos los pasos siguientes:

* Ordenamos la muestra de menor a mayor: $x_{(1)}< x_{(2)}<\cdots< x_{(n)}$.


## Test de Kolmogorov-Smirnov (K-S test)
* Calculamos la **función de distribución muestral** $F_{n}$
de esta muestra, definida de la forma siguiente:
$$
F_n(x)=\left\{\begin{array}{ll}
0, &\mbox{ si } x< x_{(1)}, \\
\dfrac{k}{n}, &\mbox{ si } x_{(k)}\leq x < x_{(k+1)},\\[2ex]
1, & \mbox{ si } x_{(n)} \leq x.
\end{array}
\right.
$$
O sea, sería la función de distribución que correspondería a la variable aleatoria discreta $X_n$ con dominio $D_X=\{x_{(1)}< x_{(2)}<\cdots< x_{(n)}\}$ y función de probabilidad $P(X_n = x_{(i)})=\frac{i}{n}$, $i=1,\ldots,n$.


## Test de Kolmogorov-Smirnov (K-S test)
El gráfico siguiente muestra la **función de distribución muestral** $F_n$ para el caso en que la muestra sean los valores $1,2,3,4,5$:

```{r,echo=FALSE,fig=TRUE,fig.align="center"}
muestra=1:5
n=length(muestra)
Fn=function(x){ifelse(x<muestra[1],0,ifelse(x<=muestra[2],1/n,ifelse(x<=muestra[3],2/n,ifelse(x<=muestra[4],3/n,ifelse(x<=muestra[5],4/n,1)))))}
xx=seq(from=-1,to=6,by=0.01)
plot(xx,Fn(xx),pch=19,cex=0.1,xlab="x",ylab=expression(F[n]))
lines(c(1,1),c(0,1/n),lty=2)
lines(c(2,2),c(1/n,2/n),lty=2)
lines(c(3,3),c(2/n,3/n),lty=2)
lines(c(4,4),c(3/n,4/n),lty=2)
lines(c(5,5),c(4/n,1),lty=2)
```


## Test de Kolmogorov-Smirnov (K-S test)
* El siguiente paso es comparar $F_n(x)$ con $F_X(x)$. Si son muy diferentes, concluimos que tenemos indicios suficientes para rechazar que la muestra proviene de la variable $X$. ¿Cómo realizamos dicha comparación?

Calculamos $\sup\{|F_n(x)-F_X(x)|\mid x\in \mathbb{R}\}$. Como $F_X$ es creciente, este supremo se alcanza en algún extremo del "escalón" de la función $F_n$.

Para calcular dicho supremo, calculamos la denominada discrepancia de cada valor $x_{(i)}$:
$$
\begin{array}{rl}
D_n(x_{(i)})& \hspace{-1.5ex} =\max\big\{| F_X(x_{(i)})-F_{n}(x_{(i)}^{-})|, |F_{X}(x_{(i)})-F_n(x_{(i)})|\big\}\\[1ex]
& \hspace{-1.5ex} \displaystyle=\max\Big\{\Big| F_X(x_{(i)})-\frac{i-1}{n}\Big|, \Big|F_{X}(x_{(i)})-\frac{i}{n}\Big|\Big\},
\end{array}$$
para todos los $i=1,\ldots, n$.

## Test de Kolmogorov-Smirnov (K-S test)
* El último paso es calcular la discrepancia máxima: 
$$
D_n=\max\big\{D_n(x_{(i)})\mid i=1,\ldots, n\big\}.
$$

El resultado interesante viene ahora: 

<l class="prop"> Teorema de Kolmogorov-Smirnov </l>
Si la hipótesis nula es cierta, la distribución límite de la variable aleatoria $\sqrt{n}\cdot D_n$ no depende de la variable $X$ y converge a la denominada **distribución de Kolmogorov** $K$. Aunque $n$ tiene que ser grande, se puede hacer un cambio de variable para que el error de aproximar $\sqrt{n}\cdot D_n$ por la **distribución de Kolmogorov** $K$ sea despreciable. Para más detalles, consultar https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test


## Test de Kolmogorov-Smirnov (K-S test)

En la práctica, se aproxima $D_n \approx \frac{1}{\sqrt{n}}\cdot K$ y se calcular el p-valor como:
$$
p=P\left(D_n > d_n\right),
$$
donde $d_n$ representa el valor obtenido de la variable $D_n$ usando nuestra muestra. La probabilidad anterior se calcula usando la función de distribución de la variable $\frac{1}{\sqrt{n}}\cdot K$. Dicha función de distribución está tabulada o hay que usar `R`.

## Ejemplo
<div class="example">
**Ejemplo**

Queremos decidir si los valores
$$
5.84,4.57,1.34,3.58,1.54,2.25
$$
provienen de una distribución normal con $\mu=3$ y $\sigma=1.5$. 

</div>


<div class="example-sol">
El contraste a realizar es el siguiente:
$$
\left\{
\begin{array}{l}
H_0: \mbox{ la muestra proviene de una $X\sim N(3,1.5)$,}\\
H_0: \mbox{ la muestra no proviene de una $X\sim N(3,1.5).$}
\end{array}
\right.
$$
Para aplicar el test K-S, primero ordenamos la muestra usando `R` "como calculadora":
```{r}
muestra=c(5.84,4.57,1.34,3.58,1.54,2.25)
(muestra.ordenada = sort(muestra))
```


</div>

```{r,echo=FALSE}
n=length(muestra)
```


## Ejemplo
<div class="example-sol">
A continuación, calculamos la **función de distribución muestral** $F_{n}$:
$$
F_n(x)=\left\{\begin{array}{ll}
0, &\mbox{ si } x< `r muestra.ordenada[1]`, \\
\frac{1}{`r n`}, & \mbox{ si } `r muestra.ordenada[1]`\leq x < `r muestra.ordenada[2]`,\\[1ex]
\frac{2}{`r n`}, & \mbox{ si } `r muestra.ordenada[2]`\leq x < `r muestra.ordenada[3]`,\\[1ex]
\frac{3}{`r n`}, & \mbox{ si } `r muestra.ordenada[3]`\leq x < `r muestra.ordenada[4]`,\\[1ex]
\frac{4}{`r n`}, & \mbox{ si } `r muestra.ordenada[4]`\leq x < `r muestra.ordenada[5]`,\\[1ex]
\frac{5}{`r n`}, & \mbox{ si } `r muestra.ordenada[5]`\leq x < `r muestra.ordenada[6]`,\\[1ex]
1, & \mbox{ si } `r muestra.ordenada[6]` \leq x,
\end{array}
\right.
$$


</div>

## Ejemplo

<div class="example-sol">
```{r,echo=FALSE,fig=TRUE,fig.align="center"}
n=length(muestra)
Fn=function(x){ifelse(x<muestra.ordenada[1],0,ifelse(x<=muestra.ordenada[2],1/n,ifelse(x<=muestra.ordenada[3],2/n,ifelse(x<=muestra.ordenada[4],3/n,ifelse(x<=muestra.ordenada[5],4/n,ifelse(x<=muestra.ordenada[6],5/n,1))))))}
xx=seq(from=-1,to=6,by=0.01)
plot(xx,Fn(xx),pch=19,cex=0.1,xlab="x",ylab=expression(F[n]))
lines(c(muestra.ordenada[1],muestra.ordenada[1]),c(0,1/n),lty=2)
lines(c(muestra.ordenada[2],muestra.ordenada[2]),c(1/n,2/n),lty=2)
lines(c(muestra.ordenada[3],muestra.ordenada[3]),c(2/n,3/n),lty=2)
lines(c(muestra.ordenada[4],muestra.ordenada[4]),c(3/n,4/n),lty=2)
lines(c(muestra.ordenada[5],muestra.ordenada[5]),c(4/n,5/n),lty=2)
lines(c(muestra.ordenada[6],muestra.ordenada[6]),c(5/n,1),lty=2)
```

</div>

## Ejemplo
<div class="example-sol">
Calculamos la **discrepancia** de cada observación $x_{(i)}$ que recordemos que vale:
$$
D_n(x_{(i)})=\max\Big\{\Big| F_X(x_{(i)})-\frac{i-1}{n}\Big|, \Big|F_{X}(x_{(i)})-\frac{i}{n}\Big|\Big\}.
$$
Esquematizamos los resultados en la tabla siguiente donde $Z$ representa la normal estándar $N(0,1)$:
</div>


## Ejemplo
<div class="example-sol">
<div class="center">
|$i$ | $x_{(i)}$ | $F_X(x_{(i)})$ | $\Big| F_X(x_{(i)})-\frac{i-1}{6}\Big|$ | $\Big|F_{X}(x_{(i)})-\frac{i}{6}\Big|$ | $D_6(x_{(i)})$|
|:--:|:----:|:----:|:----:|:----:|:----:|
$1$ | $`r muestra.ordenada[1]`$| $F_X(`r muestra.ordenada[1]`)=F_Z\left(\frac{`r muestra.ordenada[1]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[1],3,1.5),3)`$| $`r round(pnorm(muestra.ordenada[1],3,1.5),3)`$ | $\left|\frac{1}{6}-`r round(pnorm(muestra.ordenada[1],3,1.5),3)`\right|$=$`r round(abs(1/6-pnorm(muestra.ordenada[1],3,1.5)),3)`$| $`r round(max(pnorm(muestra.ordenada[1],3,1.5),abs(1/6-pnorm(muestra.ordenada[1],3,1.5))),3)`$|
$2$ | $`r muestra.ordenada[2]`$| $F_X(`r muestra.ordenada[2]`)=F_Z\left(\frac{`r muestra.ordenada[2]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[2],3,1.5),3)`$| $\left|`r round(pnorm(muestra.ordenada[2],3,1.5),3)`-\frac{1}{6}\right|=`r round(abs(1/6-pnorm(muestra.ordenada[2],3,1.5)),3)`$ | $\left|`r round(pnorm(muestra.ordenada[2],3,1.5),3)`-\frac{2}{6}\right|=`r round(abs(2/6-pnorm(muestra.ordenada[2],3,1.5)),3)`$| $`r round(max(abs(1/6-pnorm(muestra.ordenada[2],3,1.5)),abs(2/6-pnorm(muestra.ordenada[2],3,1.5))),3)`$|
$3$ | $`r muestra.ordenada[3]`$| $F_X(`r muestra.ordenada[3]`)=F_Z\left(\frac{`r muestra.ordenada[3]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[3],3,1.5),3)`$| $\left|`r round(pnorm(muestra.ordenada[3],3,1.5),3)`-\frac{2}{6}\right|=`r round(abs(2/6-pnorm(muestra.ordenada[3],3,1.5)),3)`$ | $\left|`r round(pnorm(muestra.ordenada[3],3,1.5),3)`-\frac{3}{6}\right|=`r round(abs(3/6-pnorm(muestra.ordenada[3],3,1.5)),3)`$| $`r round(max(abs(2/6-pnorm(muestra.ordenada[3],3,1.5)),abs(3/6-pnorm(muestra.ordenada[3],3,1.5))),3)`$|
$4$ | $`r muestra.ordenada[4]`$| $F_X(`r muestra.ordenada[4]`)=F_Z\left(\frac{`r muestra.ordenada[4]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[4],3,1.5),3)`$| $\left|`r round(pnorm(muestra.ordenada[4],3,1.5),3)`-\frac{3}{6}\right|=`r round(abs(3/6-pnorm(muestra.ordenada[4],3,1.5)),3)`$ | $\left|`r round(pnorm(muestra.ordenada[4],3,1.5),3)`-\frac{4}{6}\right|=`r round(abs(4/6-pnorm(muestra.ordenada[4],3,1.5)),3)`$| $`r round(max(abs(3/6-pnorm(muestra.ordenada[4],3,1.5)),abs(4/6-pnorm(muestra.ordenada[4],3,1.5))),3)`$|
$5$ | $`r muestra.ordenada[5]`$| $F_X(`r muestra.ordenada[5]`)=F_Z\left(\frac{`r muestra.ordenada[5]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[5],3,1.5),3)`$| $\left|`r round(pnorm(muestra.ordenada[5],3,1.5),3)`-\frac{4}{6}\right|=`r round(abs(4/6-pnorm(muestra.ordenada[5],3,1.5)),3)`$ | $\left|`r round(pnorm(muestra.ordenada[5],3,1.5),3)`-\frac{5}{6}\right|=`r round(abs(5/6-pnorm(muestra.ordenada[5],3,1.5)),3)`$| $`r round(max(abs(4/6-pnorm(muestra.ordenada[5],3,1.5)),abs(5/6-pnorm(muestra.ordenada[5],3,1.5))),3)`$|
$6$ | $`r muestra.ordenada[6]`$| $F_X(`r muestra.ordenada[6]`)=F_Z\left(\frac{`r muestra.ordenada[6]`-3}{1.5}\right)=`r round(pnorm(muestra.ordenada[6],3,1.5),3)`$| $\left|`r round(pnorm(muestra.ordenada[6],3,1.5),3)`-\frac{5}{6}\right|=`r round(abs(5/6-pnorm(muestra.ordenada[6],3,1.5)),3)`$ | $\left|`r round(pnorm(muestra.ordenada[6],3,1.5),3)`-1\right|=`r round(abs(1-pnorm(muestra.ordenada[6],3,1.5)),3)`$| $`r round(max(abs(5/6-pnorm(muestra.ordenada[6],3,1.5)),abs(1-pnorm(muestra.ordenada[6],3,1.5))),3)`$|
</div>
</div>


## Ejemplo
<div class="example-sol">
El valor del **estadístico** $D_6$ será el máximo de la última columna de la tabla anterior: $D_6 =0.191.$

De cara a hallar el p-valor tenemos que consultar **la tabla del test de Kolmogorov-Smirnov**. Si vais a http://images.google.com y escribís "tabla de dn Kolmogorov" en la casilla de búsqueda, encontraréis un montón de tablas de la variable $D_n$. 

La primera fila de dichas tablas corresponde al **error tipo I del contraste** y la primera columna, al tamaño de la muestra $n$. 

Si os fijáis en la fila correspondiente a $n=6$, veréis que el valor de $D_6=0.191$ no sale, lo que significa que el valor $\alpha$ debe ser mayor que 0.2. Por tanto, nuestro p-valor será mayor que 0.2, hecho que nos hace concluir que no tenemos indicios suficientes para rechazar que la muestra se distribuya según una distribución normal $N(\mu=3,\sigma=1.5)$.
</div>

## Contraste K-S en `R`
La función básica para realizar el test K-S es `ks.test`. Su sintaxis
básica para una muestra es
```{r, eval=FALSE}
ks.test(x, y, parámetros)
```

donde:

* `x` es la muestra de una variable continua.

* `y` puede ser un segundo vector, y entonces se contrasta si ambos vectores han sido generados por la misma distribución continua, o el nombre de la función de distribución (empezando con `p`) que queremos contrastar, entre comillas; por ejemplo `"pnorm"` para
la distribución normal.

* Los `parámetros` de la función de distribución si se ha especificado una; por
ejemplo `mean=0, sd=1` para una distribución normal estándar.

## Ejemplo en `R`
<div class="example-sol">
Para realizar el contraste K-S para nuestro ejemplo, tenemos que hacer lo siguiente:
```{r}
ks.test(muestra,"pnorm",mean=3,sd=1.5)
```
Observamos que nos da el mismo valor de **discrepancia máxima** que hemos obtenido anteriormente con un p-valor altísimo, hecho que corrobora la conclusión que hemos escrito.

</div>

# Test de normalidad

## Test de Kolmogorov-Smirnov-Lilliefors (K-S-L)

Para contrastar si una muestra proviene de una distribución normal con los parámetros $\mu$ y $\sigma$ desconocidos, el **test K-S** nos "obliga" a darles un valor.

Los valores "óptimos" para dichos parámetros serían las estimaciones dadas por los **estimadores de máxima verosimilitud**: la **media muestral** para $\mu$ y la **desviación típica muestral** para sigma. 

La **prueba de Kolmogorov-Smirnov-Lilliefors** consiste en estimar dichos parámetros, calcular la **discrepancia máxima** tal como hemos explicado pero a la hora de calcular el p-valor, se usa otra distribución, llamada **distribución de Lilliefors** en lugar de usar la **distribución de Kolmogorov** ya que con la **distribución de Lilliefors**, el contraste es más robusto.



## Test K-S-L en `R`
<div class="example">
Vamos a aplicar el **test K-S-L** a nuestra muestra anterior para ver si se distribuye según la ley normal.

El **test K-S-L** test en `R` se aplica usando la función `lillie.test` del paquete `nortest`:
```{r}
library(nortest)
lillie.test(muestra)
```
Vemos que el p-valor no es tan grande como en el caso anterior pero aún así, es suficientemente grande para concluir que no tenemos indicios suficientes para rechazar que nuestra muestra siga la distribución normal.
</div>

## Test K-S-L

El test K-S-L tiene un inconveniente: aunque es muy sensible a las diferencias entre la muestra y la distribución teórica alrededor de sus valores medios, le cuesta detectar diferencias prominentes en un extremo u otro de la distribución. 

Su potencia se ve afectada por dicho inconveniente.

## Test K-S-L
Veamos un ejemplo de este hecho intentando ver si una muestra de una distribución $t$ de Student nos acepta que es normal o no:
```{r}
set.seed(100)
x=rt(50,3)
lillie.test(x)
```
## Test K-S-L

Nos dice que no podemos rechazar que la muestra `x` sea normal. 

Esto es debido a que la función de densidad de la distribución $t$ de Student es algo más aplanada que la distribución normal, donde en los dos extremos está por encima de la de la normal. 

Como el test K-S-L no detecta las diferencias en los extremos, acepta que `x` es normal.

## Test de normalidad de Anderson-Darling (A-D)
El **test de normalidad de Anderson-Darling** resuelve el inconveniente del **test de K-S-L**.

Este test está implementado en la función `ad.test` del paquete `nortest`. 

Si ahora, aplicamos el **test A-D** a la muestra anterior de la distribución $t$ de Student, la normalidad queda rechazada:
```{r}
ad.test(x)
```
## Test de normalidad de Anderson-Darling (A-D)

Un inconveniente común a los **tests K-S-L y A-D** es que, si bien pueden usarse con muestras pequeñas (pongamos de más de 5 elementos), se comportan mal con muestras grandes, de varios miles de elementos. 

En muestras de este tamaño, cualquier pequeña divergencia de la normalidad se magnifica y en estos dos tests aumenta la probabilidad de errores de tipo I.


## Test de Shapiro-Wilks (S-W)
Un test que resuelve este problema es el de **Shapiro-Wilk** (**S-W**), implementado en la función  `shapiro.test` de la instalación básica de `R`.

Apliquemos el **test S-W** a las dos muestras anteriores: la muestra del ejemplo y la muestra de la distribución $t$ de Student:


## Test de Shapiro-Wilks (S-W)
```{r}
shapiro.test(muestra)
shapiro.test(x)
```
## Test de Shapiro-Wilks (S-W)
Vemos que acepta que la muestra del ejemplo anterior sea normal y rechaza la normalidad en el caso de la muestra de la $t$ de Student.

Si nuestra muestra de valores tiene empates, los p-valores de los contrastes calculados a partir de las distribuciones de los estadísticos usados en los tests **K-S-L**, **A-D** y **S-W** se pueden ver afectados hasta el punto de que, si hay muchos empates, su significado no tenga ningún sentido. 

Hay que decir que el menos afectado por los empates es el test de **S-W**.


## Test omnibus de D'Agostino-Pearson
Un test que no es sensible a los empates es el test de normalidad de **D'Agostino-Pearson**.

Este test se encuentra implementado en la función `dagoTest` del paquete **fBasics**, y lo que hace es cuantificar lo diferentes que son la asimetría y la curtosis de la muestra (dos parámetros estadísticos relacionados con la forma de la gráfica de la función de densidad muestral)  respecto de los esperados en una distribución normal, y resume esta discrepancia en un p-valor con el significado usual.

Para poder aplicar dicho test, el tamaño de la muestra debe ser 20 como mínimo.

Por tanto, sólo podemos aplicar dicho test a la muestra de datos correspondiente a la distribución $t$ de Student:

## Test omnibus de D'Agostino-Pearson

```{r,warning=FALSE,message=FALSE}
library(fBasics)
dagoTest(x)
```
## Test omnibus de D'Agostino-Pearson
Si nos fijamos en el resultado, el test calcula tres estadísticos de contraste: el test **Omnibus** basado en la distribución $\chi^2$, el test de asimetría y el test de curtosis con sus correspondientes p-valores. Para más información, id a https://en.wikipedia.org/wiki/D%27Agostino%27s_K-squared_test

Vemos que según el test de **D'Agostino-Pearson**, la muestra `x` correspondiente a la distribución $t$ de Student no sigue la ley normal.


## Guía rápida

* `qqPlot` del paquete **car**, sirve para dibujar un Q-Q-plot de una muestra contra una distribución teórica.  Sus parámetros principales son:

    * `distribution`: el nombre de la familia de distribuciones, entre comillas.
    * Los parámetros de la distribución: `mean` para la media, `sd` para la desviación típica, `df` para los grados de libertad, etc.
    *  Los parámetros usuales de `plot`.

## Guía rápida

* `chisq.test` sirve para realizar tests $\chi^2$ de bondad de ajuste. Sus parámetros principales son:

    * `p`: el vector de probabilidades teóricas.
    *  `rescale.p`: igualado a `TRUE`, indica que  los valores de `p` no son probabilidades, sino sólo proporcionales a las probabilidades.
    *  `simulate.p.value`: igualado a `TRUE`, R calcula el p-valor mediante simulaciones.
    *  `B`: en este último caso, permite especificar el número de simulaciones.


## Guía rápida

* `ks.test` realiza el test de Kolmogorov-Smirnov. Tiene dos tipos de uso:

    * `ks.test(x,y)`: contrasta si los vectores `x` e `y`  han sido generados por la misma distribución continua.
    * `ks.test(x, "distribución", parámetros)`: contrasta si el vector `x`  ha sido generado por la distribución especificada, que se ha de indicar con el nombre de la función de distribución de R  (la que empieza con p).

*  `lillie.test` del paquete **nortest**, realiza el test de normalidad de Kolmogorov-Smirnov-Lilliefors.

*  `ad.test` del paquete **nortest**, realiza el test de normalidad de Anderson-Darling.

*  `shapiro.test`, realiza el test de normalidad de Shapiro-Wilk.

*  `dagoTest` del paquete **fBasics**, realiza el test ómnibus de D'Agostino-Pearson.