---
title: "Tema 6 - Contrastes de independencia y homogeneidad"
author: "Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir"
date: 
output: 
  ioslides_presentation:
    widescreen: true
    css: Mery_style.css
    logo: Images/matriz_mov.gif
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Contrastes de independencia

## Introducción

Una de las aplicaciones más usadas del test de bondad de ajuste es contrastar si dos maneras de clasificar $n$ objetos son **independientes** o no.

Veamos un ejemplo ilustrativo:

<div class="example">
**Ejemplo**

En un estudio de una vacuna de hepatitis  participan 1083 voluntarios. De éstos, se eligen aleatoriamente 549 y son vacunados. Los otros, 534, no son vacunados. Después de un cierto tiempo, se observa que 70 de los 534 no vacunados han contraído la hepatitis, mientras que sólo 11 de los 549 vacunados la han contraído.

Esquematicemos los resultados en lo que se llama una tabla de contingencia:

</div>

## Introducción
<div class="example">
<div class="center">
| ¿Enfermó?/¿Vacunado? | Sí    | No | Total |
|----------|-----|----|----|
| Sí   | 11 | 70| `r 11+70` |
| No  | 538 | 464 | `r 538+464` |
| Total| `r 11+538` | `r 70+464`| `r 11+538+70+464`|
</div>

¿Es el hecho de contraer hepatitis independiente de haber sido vacunado contra la dolencia?

En este ejemplo, contrastar si la manera de clasificar a los voluntarios entre vacunados y no vacunados y la manera de clasificarlos entre enfermos por hepatitis y no enfermos es equivalente a contrastar si la vacuna es efectiva contra la hepatitis. 

Decir que la vacuna no es efectiva sería equivalente a decir que vacunar a un individuo es independiente de que contraiga la hepatitis.
</div>

## Tablas de contingencia
La situación en general sería la siguiente:

Tenemos $n$ individuos y los clasificamos según dos criterios: $X$ e $Y$. Sean $x_1,\ldots, x_I$ los distintos **niveles** del criterio $X$ e $y_1,\ldots, y_J$, los distintos **niveles** del criterio $Y$.

En el ejemplo anterior $I=J=2$, $X$ sería el criterio de clasificación por vacunación con $x_1:$"vacunados" y $x_2:$"no vacunados" e $Y$ sería el criterio de clasificación por contracción de la hepatitis con $y_1:$"enfermo de hepatitis" e $y_2:$"no enfermo de hepatitis".

Definimos $n_{ij}$ como el número de individuos clasificados en el nivel $x_i$ según el criterio $X$ y clasificados en el nivel $y_j$ según el criterio $Y$. A partir de dichos valores construimos la denominada **tabla de contingencia**:

## Tablas de contingencia
<div class="center">
$X/Y$ | $y_1$ | $\ldots$ | $y_j$ | $\ldots$| $y_J$ | $n_{i \bullet}$ |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|$x_1$ | $n_{11}$  | $\ldots$ | $n_{1j}$ | $\ldots$ | $n_{1J}$ | $n_{1\bullet}$ |
|$\vdots$ | $\vdots$  | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
|$x_i$ | $n_{i1}$ |  $\ldots$ | $n_{ij}$ | $\ldots$ | $n_{iJ}$ | $n_{i \bullet}$ |
|$\vdots$ | $\vdots$  | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
|$x_I$ | $n_{I1}$ | $\ldots$ | $n_{Ij}$ | $\ldots$ | $n_{IJ}$ | $n_{I \bullet}$ |
$n_{\bullet j}$ | $n_{\bullet 1}$  | $\ldots$ | $n_{\bullet j}$ | $\ldots$ | $n_{\bullet J}$ | $n$ 
</div>

## Tablas de contingencia
En la tabla anterior, $n_{i\bullet}$ sería el número total de individuos clasificados en el nivel $x_i$ según el criterio $X$ y $n_{\bullet j}$, el número total de individuos clasificados en el nivel $y_j$ según el criterio $Y$.

El contraste que nos planteamos es el siguiente:
$$
\left.
\begin{array}{ll}
H_0: \mbox{ Los criterios de clasificación $X$ e $Y$ son independientes,}\\
H_1: \mbox{ Los criterios de clasificación $X$ y $Y$ no son independientes.}
\end{array}
\right\}
$$
Para poder realizar el contraste anterior, lo plantearemos como un contraste de **bondad de ajuste.**

## Contraste de independencia como un contraste de bondad de ajuste

Para poder modelar el contraste de independencia como un contraste de **bondad de ajuste**, en primer lugar necesitamos definir una variable "modelo".

A partir de nuestros datos empíricos, contrastaremos si dichos datos siguen la variable "modelo" usando el test de la $\chi^2$ de bondad de ajuste.

Nuestra variable "modelo" será una variable aleatoria discreta **bidimensional** $(X,Y)$ con dominio $\{(x_1,y_1),\ldots,(x_I,y_J)\}$, o, si se quiere $\{(x_i,y_j)\ |\ i=1,\ldots, I, \ j=1,\ldots,J\}$. Sería una variable con $I\cdot J$ valores.

## Contraste de independencia como un contraste de bondad de ajuste
Para calcular la función de probabilidad de la variable $(X,Y)$, hay que suponer que la hipótesis nula $H_0$ es cierta o que los criterios $X$ e $Y$ son **independientes**. Por tanto:
$$
P((X,Y)=(x_i,y_j))=P(X=x_i)\cdot P(Y=y_j)=\frac{n_{i\bullet}}{n}\cdot \frac{n_{\bullet j}}{n}=\frac{n_{i\bullet}\cdot n_{\bullet j}}{n^2},
$$
$i=1,\ldots, I$, $j=1,\ldots,J$.

Los valores $n_{ij}$ serían los **valores empíricos** con los que hay que contrastar si siguen la distribución de la variable $(X,Y)$.

## Test $\chi^2$ de independencia
Una vez planteado el contraste de independencia como una contraste de **bondad de ajuste**, recordemos que el **test $\chi^2$** asociado al contraste es:
$$
\chi^2=\sum_{i=1}^I\sum_{j=1}^J \frac{\left( n_{ij}-n\cdot P((X,Y)=(x_i,y_j))\right)^2 }{n\cdot P((X,Y)=(x_i,y_j))}
=\sum_{i=1}^I\sum_{j=1}^J \frac{\left( n_{ij}-\frac{n_{i\bullet}\cdot n_{\bullet j}}{n}\right)^2 }{\frac{n_{i\bullet}\cdot n_{\bullet j}}{n}},
$$
donde las frecuencias $n_{ij}$ serían las **frecuencias observadas** y las frecuencias $\frac{n_{i\bullet}\cdot n_{\bullet j}}{n}$ serían las **frecuencias esperadas**.

Recordemos que si $n$ es grande y cada frecuencia esperada $\frac{n_{i\bullet}\cdot n_{\bullet j}}{n}$ es $\geq 5$,  este estadístico sigue aproximadamente una ley $\chi^2$ con $(I-1) \cdot (J -1)$ **grados de libertad**.

## Test $\chi^2$ de independencia
<l class="observ">Observación.</l>

¿Por qué los **grados de libertad** del **estadístico de contraste** son $(I-1)\cdot (J-1)$?

La razón es la siguiente: recordemos que al realizar un **test de bondad de ajuste**, los **grados de libertad** del estadístico $\chi^2$ era:
$g.l.=\mbox{número de clases}-\mbox{número de parámetros estimados}-1.$

Fijémonos que en el contraste de independencia hemos estimado $I+J-2$ **parámetros** que corresponden a las **medias de las variables $X$ e $Y$**: $\frac{n_{i\bullet}}{n}$ y $\frac{n_{\bullet j}}{n}$, $i=1,\ldots, I$, $j=1,\ldots,J$.

En nuestro caso, nos queda:
$$
g.l. =I\cdot J-(I+J-2)-1=(I-1)\cdot (J-1).
$$


## Test $\chi^2$ de independencia
Como siempre, sea $\chi_0$ el valor que toma el **estadístico de contraste**. El **p-valor** del contraste es:
$$
p=P(\chi_{(I-1) \cdot (J -1)}^2\geq \chi_0),
$$
con el significado usual: 

* si $p<0.05$, concluimos que tenemos evidencias suficientes para rechazar la independencia de los criterios,
* si $p>0.1$, concluimos que no tenemos evidencias suficientes para rechazar la independencia de los criterios y,
* si $0.05\leq p\leq 0.1$, estamos en la zona de penumbra. Necesitamos más datos para tomar una decisión clara.

## Ejemplo
<div class="example">
**Ejemplo del estudio de la vacuna de hepatitis**

Recordemos que la tabla de contingencia de dicho estudio era:
<div class="center">
| ¿Enfermó?/¿Vacunado? | Sí    | No | Total |
|----------|-----|----|----|
| Sí   | 11 | 70| `r 11+70` |
| No  | 538 | 464 | `r 538+464` |
| Total| `r 11+538` | `r 70+464`| `r 11+538+70+464`|
</div>

</div>


## Ejemplo
<div class="example">
A continuación, calculemos la tabla de las frecuencias esperadas $\frac{n_{i\bullet}\cdot n_{\bullet j}}{n}$ a partir de las sumas de las filas y las columnas anteriores:

<div class="center">
| ¿Enfermó?/¿Vacunado? | Sí    | No | Total |
|----------|-----|----|----|
| Sí   | $\frac{`r 11+70`\cdot `r 11+538`}{`r 11+538+70+464`}=`r round((11+70)*(11+538)/(11+538+70+464),3)`$ | $\frac{`r 11+70`\cdot `r 70+464`}{`r 11+538+70+464`}=`r round((11+70)*(70+464)/(11+538+70+464),3)`$| `r 11+70` |
| No  | $\frac{`r 538+464`\cdot `r 11+538`}{`r 11+538+70+464`}=`r round((538+464)*(11+538)/(11+538+70+464),3)`$ | $\frac{`r 538+464`\cdot `r 70+464`}{`r 11+538+70+464`}=`r round((538+464)*(70+464)/(11+538+70+464),3)`$ | `r 538+464` |
| Total| `r 11+538` | `r 70+464`| `r 11+538+70+464`|
</div>
</div>


## Ejemplo
<div class="example">
El valor del estadístico de contraste será:
$$
\chi_0 = \frac{(11-`r round((11+70)*(11+538)/(11+538+70+464),3)`)^2}{`r round((11+70)*(11+538)/(11+538+70+464),3)`}+\frac{(70-`r round((11+70)*(70+464)/(11+538+70+464),3)`)^2}{`r round((11+70)*(70+464)/(11+538+70+464),3)`}+ \frac{(538-`r round((538+464)*(11+538)/(11+538+70+464),3)`)^2}{`r round((538+464)*(11+538)/(11+538+70+464),3)`}+\frac{(464-`r round((538+464)*(70+464)/(11+538+70+464),3)`)^2}{`r round((538+464)*(70+464)/(11+538+70+464),3)`}=`r round(chisq.test(matrix(c(11,538,70,464),2,2),correct=FALSE)[[1]],3)`.
$$
El p-valor del contraste será:
$$
p=P(\chi^2_1 > `r round(chisq.test(matrix(c(11,538,70,464),2,2),correct=FALSE)[[1]],3)`) = `r round(pchisq( chisq.test(matrix(c(11,538,70,464),2,2),correct=FALSE)[[1]],1,lower.tail=FALSE),3)`.
$$
Como el p-valor es muy pequeño, de hecho despreciable, concluimos que tenemos suficientes evidencias para rechazar que la vacuna y la hepatitis son independientes. O sea, vacunarse afecta al hecho de contraer la enfermedad.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Un investigador quiere saber si el número de crías por loba es independiente de la zona donde viva. Para ello, considera 3 zonas ($X$): $X_1=$"Norte", $X_2=$"Centro" y $X_3=$"Sur".

Clasifica los números de crías ($Y$) en
$Y_1=$" Dos o menos", $Y_2=$" Entre tres y cinco",  $Y_3=$"Entre seis y ocho" y $Y_4=$"Nueve  o más".

Queremos hacer el contraste:
$$
\left.
\begin{array}{ll}
H_0: \mbox{ El número de crías por loba es independiente de la zona,}\\
H_1: \mbox{ El número de crías por loba no es independiente de la zona.}
\end{array}
\right\}
$$
</div>

## Ejemplo
<div class="example">

Toma una muestra de 200 lobas y obtiene la tabla siguiente:
<div class="center">
$X/Y$ | $Y_1$ | $Y_2$ | $Y_3$ | $Y_4$ | $n_{i\bullet}$|
|---|---|---|---|---|---|
|$X_1$ | 5   | 8   | 15  | 22   | 50 |
|$X_2$ | 20 |26  |46   | 8  | 100|
|$X_3$ | 15  | 10  | 15   | 10   | 50 | 
|$n_{\bullet j}$ | 40 | 44 | 76 | 40 | 200 |  
</div>


</div>


## Ejemplo
<div class="example">
Las frecuencias esperadas si las variables son independientes son:
<div class="center">
$X/Y$ | $Y_1$ | $Y_2$ | $Y_3$ | $Y_4$ | $n_{i\bullet}$|
|---|---|---|---|---|---|
|$X_1$ |  10 |  11 |  19 |  10 | 50 |
|$X_2$ |  20 | 22 | 38 |  20 | 100 |
|$X_3$ |  10 |  11 |  19 |  10 | 50 |
|$n_{\bullet j}$ | 40 | 44 | 76 | 40 | 200 |
</div>


</div>


## Ejemplo
<div class="example">
El valor del estadístico de contraste será:
$$
\begin{array}{rl}
\chi_0  = & \frac{(5-10)^2}{10}+\frac{(8-11)^2}{11}+\frac{(15-19)^2}{19}+\frac{(22-10)^2}{10}+
\frac{(20-20)^2}{20}+\frac{(26-22)^2}{22}\\ & +\frac{(46-38)^2}{38}+\frac{(8-20)^2}{20}+\frac{(15-10)^2}{10}+\frac{(10-11)^2}{11}+\frac{(15-19)^2}{19}+\frac{(10-10)^2}{10} = `r round(chisq.test(matrix(c(5,20,15,8,26,10,15,46,15,22,8,10),3,4),correct=FALSE)[[1]],3)`.
\end{array}
$$
El p-valor del contraste vale:
$$
p=P(\chi^2_{6} > `r round(chisq.test(matrix(c(5,20,15,8,26,10,15,46,15,22,8,10),3,4),correct=FALSE)[[1]],3)`) =`r round(pchisq(chisq.test(matrix(c(5,20,15,8,26,10,15,46,15,22,8,10),3,4),correct=FALSE)[[1]],6,lower.tail=FALSE),3)`.
$$
Como el p-valor es muy pequeño, de hecho despreciable, concluimos que tenemos suficientes evidencias para rechazar que el número de crías y la zona donde viven las lobas son independientes.
</div>

## Contraste de independencia en `R`
Para realizar un contraste de independencia en `R` hay que usar la función `chisq.test(tabla.contingencia,correct)` con los parámetros siguientes:

* `tabla.contingencia`: es la tabla de las frecuencias empíricas.
* `correct`: es un parámetro lógico. Si su valor es `FALSE`, hará los cálculos como hemos explicado. Si su valor es `TRUE`, aplica la corrección a la continuidad sólo para tablas de contingencia $2\times 2$. (Ver https://es.wikipedia.org/wiki/Correcci%C3%B3n_de_Yates)

## Contraste de independencia en `R`
<div class="example">
**Ejemplo del estudio de la vacuna de hepatitis**

Para realizar el contraste de independencia en `R` hacemos lo siguiente:

```{r}
chisq.test(matrix(c(11,538,70,464),2,2),correct=FALSE)
```
Observamos que obtenemos los mismos valores que en los cálculos hechos a mano.
</div>

## Ejemplo
<div class="example">
**Ejemplo del estudio del número de crías de una loba y la zona donde vive**

En este ejemplo, para realizar el contraste en `R`, basta hacer:
```{r}
chisq.test(matrix(c(5,20,15,8,26,10,15,46,15,22,8,10),3,4))
```
En este caso, también se obtienen los mismos valores que en los cálculos realizados anteriormente.

</div>


## Contraste de independencia en `R`
<div class="example">
**Ejemplo**

La tabla de datos `WorldPhones` de `R` nos da el número de teléfonos (en miles de unidades) que había en distintas regiones del mundo en los años 1951, 1956, 1957, 1958, 1959, 1960 y 1961:
```{r}
WorldPhones
```
Como puede observarse, las regiones son: Norte América, Europa, Asia, Sudamérica, Oceanía, África y América Central.
</div>

## Contraste de independencia en `R`
<div class="example">
Vamos a contrastar si el año es independiente de la región para el hecho de tener teléfono o no.

Para hallar las distribuciones marginales de las variables "Año" y "Región" hemos de usar la función `addmargins`:
```{r}
(Tabla.con.marginales = addmargins(WorldPhones))
```

</div>


## Contraste de independencia en `R`
<div class="example">
La tabla de frecuencias esperadas sería:

```{r}
(tabla.frec.esperadas = rowSums(WorldPhones)%*%t(colSums(WorldPhones)))/sum(WorldPhones)
```
</div>

## Contraste de independencia en `R`
<div class="example">
Para realizar el contraste, usamos tal como hemos indicado la función `chisq.test`:
```{r}
chisq.test(WorldPhones)
```
Vemos que el p-valor es depreciable. Concluimos que tenemos evidencias suficientes para rechazar que el año y la zona son independientes respecte del hecho de tener teléfono o no.
</div>

## Caso en que las frecuencias esperadas son inferiores a 5

Si algunas frecuencias absolutas esperadas son inferiores a 5, la
aproximación del p-valor por una distribución $\chi^2$ podría no ser adecuada.

Si se da esta situación, lo mejor es recurrir a simular el p-valor usando el parámetro
`simulate.p.value=TRUE`.

Veamos un ejemplo en el que se da esta situación:

## Ejemplo

<div class="example">
Consideremos la tabla de datos `iris`. Nos planteamos si la especie de la flor es independiente de la longitud del pétalo.

En primer lugar, hallamos la tabla de contingencia de las dos variables (especie y longitud del pétalo), agrupando en cuatro clases la variable continua "Longitud del pétalo":
```{r}
(tabla.contingencia =table(cut(iris$Petal.Length,4),iris$Species))
```

</div>

## Ejemplo

<div class="example">
Calculemos a continuación la tabla de frecuencias esperadas:
```{r}
(tabla.frec.esperadas = rowSums(tabla.contingencia)%*%t(colSums(tabla.contingencia))
 /sum(tabla.contingencia))
```
¡Uy! Observamos que hay frecuencias esperadas menores que 5. 

</div>

## Ejemplo

<div class="example">

Veamos que pasa si usamos la función `chisq.test`:
```{r}
chisq.test(tabla.contingencia)
```
`R` nos avisa que la aproximación puede ser incorrecta debido al hecho de que tenemos frecuencias esperadas menores que 5.

</div>


## Ejemplo

<div class="example">
Para resolver este inconveniente, simularemos el valor del p-valor reiniciando la semilla a `NULL`:
```{r}
set.seed(NULL)
chisq.test(tabla.contingencia,simulate.p.value = TRUE, B=5000)
```
El parámetro `B` indica el número de replicaciones que hemos de realizar en nuestra simulación. 

Observamos que el p-valor es pequeño. Por tanto, concluimos que tenemos evidencias suficientes para rechazar que la longitud del pétalo y la especie sean independientes.

</div>

## Diseño experimental en el contraste de independencia

En un **contraste de independencia** se toma una **muestra transversal** de la población, es decir, se selecciona al azar una cierta cantidad de individuos de la población, se observan las dos variables sobre cada uno de ellos, y se contrasta si las probabilidades conjuntas son iguales al producto de las probabilidades marginales de cada variable. 


En el ejemplo de la vacuna y la hepatitis, seleccionamos una muestra de 1083 individuos de toda la población, y los clasificamos en 4 subgrupos: los que han sido vacunados y han contraído la enfermedad (ha habido 11), los que no han sido vacunados y han contraído la enfermedad (ha habido 70), los que han sido vacunados y no han contraído la enfermedad (ha habido 538) y, por último, los que no han sido vacunados y no han contraído la enfermedad (ha habido 534).

# Contrastes de homogeneidad

## Introducción

En un contraste de homogeneidad, tenemos dos variables discretas $X$ e $Y$ y nos planteamos si la distribución de la variable $Y$ depende de los valores de la variable $X$. 

El contraste planteado es el siguiente:
$$
\left.
\begin{array}{ll}
H_0: & \mbox{ La distribución de la variable condicional $Y|X=x$} \\ & \mbox{es la misma para cualquier valor de $x$ del dominio de la variable $X$,}\\
H_1: & \mbox{ La distribución de la variable condicional $Y|X=x$} \\ & \mbox{no es la misma para cualquier valor de $x$.}
\end{array}
\right\}
$$


## Tablas de contingencia
Para realizar un contraste de homogeneidad, tenemos al igual que en el contraste de independencia $n$ individuos clasificados según la variables $X$ e $Y$. 

Recordemos que $x_1,\ldots, x_I$ los distintos **valores** de la variable $X$ e $y_1,\ldots, y_J$, los distintos **valores** de la variable $Y$.

Recordemos también que $n_{ij}$ es el número de individuos clasificados en valor $x_i$ según la variable $X$ y clasificados en el valor $y_j$ según la variable $Y$. A partir de dichos valores construimos lo que hemos definido como la **tabla de contingencia**:

## Tablas de contingencia
<div class="center">
$X/Y$ | $y_1$ | $\ldots$ | $y_j$ | $\ldots$| $y_J$ | $n_{i \bullet}$ |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|$x_1$ | $n_{11}$  | $\ldots$ | $n_{1j}$ | $\ldots$ | $n_{1J}$ | $n_{1\bullet}$ |
|$\vdots$ | $\vdots$  | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
|$x_i$ | $n_{i1}$ |  $\ldots$ | $n_{ij}$ | $\ldots$ | $n_{iJ}$ | $n_{i \bullet}$ |
|$\vdots$ | $\vdots$  | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
|$x_I$ | $n_{I1}$ | $\ldots$ | $n_{Ij}$ | $\ldots$ | $n_{IJ}$ | $n_{I \bullet}$ |
|$n_{\bullet j}$ | $n_{\bullet 1}$  | $\ldots$ | $n_{\bullet j}$ | $\ldots$ | $n_{\bullet J}$ | $n$ 
</div>

## Tablas de contingencia
En la tabla anterior, $n_{i\bullet}$ sería el número total de individuos clasificados en el nivel $x_i$ según el criterio $X$ y $n_{\bullet j}$, el número total de individuos clasificados en el nivel $y_j$ según el criterio $Y$.


## Contraste de homogeneidad como un contraste de bondad de ajuste

Para poder modelar el contraste de homogeneidad como un contraste de **bondad de ajuste**, en primer lugar necesitamos definir una variable "modelo".

La fila $i$-ésima de la **tabla de contingencia** anterior representa la tabla de **frecuencias empíricas** de la variable $Y|X=x_i$:

<div class="center">
$Y|X=x_i$ | $y_1$ | $\ldots$ | $y_j$ | $\ldots$| $y_J$ | Total |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| | $n_{i1}$ |  $\ldots$ | $n_{ij}$ | $\ldots$ | $n_{iJ}$ | $n_{i \bullet}$ | 
</div>


## Contraste de homogeneidad como un contraste de bondad de ajuste
Si la hipótesis nula es cierta, o, si la distribución de la variable condicionada $Y|X=x_i$ es la misma para cualquier $x_i$, significa que la distribución de cada fila "coincidirá" con la distribución de la última fila de la tabla de contingencia:

<div class="center">
$Y|X=x$ | $y_1$ | $\ldots$ | $y_j$ | $\ldots$| $y_J$ | Total |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| | $n_{\bullet 1}$  | $\ldots$ | $n_{\bullet j}$ | $\ldots$ | $n_{\bullet J}$ | $n$ 
</div>

Dicha variable será nuestra **variable "modelo"**. Nuestro problema será, pues, chequear si la distribución de las **frecuencias empíricas** (fila $i$-ésima de la **tabla de contingencia**) coincide con la distribución de las **frecuencias teóricas** (última fila de la **tabla de contingencia**). ¿Pero cómo podemos compararlas si, en principio tendrán tamaño diferente?

## Contraste de homogeneidad como un contraste de bondad de ajuste
Antes de poder aplicar toda la maquinaría del contraste $\chi^2$ de bondad de ajuste, necesitamos que la suma de las **frecuencias empíricas** coincida con la suma de las **frecuencias teóricas**. 

La suma de las **frecuencias empíricas** vale $n_{i\bullet}$ y la suma de las **frecuencias teóricas**, $n$.

## Contraste de homogeneidad como un contraste de bondad de ajuste

Para "forzar" que las dos sumas sean iguales, multiplicaremos las **frecuencias teóricas** por $\frac{n_{i\cdot}}{n}$. Así, la tabla de **frecuencias teóricas** quedará:

<div class="center">
$Y|X=x$ | $y_1$ | $\ldots$ | $y_j$ | $\ldots$| $y_J$ | Total |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| | $\frac{n_{i\bullet} n_{\bullet 1}}{n}$  | $\ldots$ | $\frac{n_{i\bullet} n_{\bullet j}}{n}$ | $\ldots$ | $\frac{n_{i\bullet} n_{\bullet J}}{n}$ | $n_{i\bullet}$ 
</div>


## Contraste de homogeneidad como un contraste de bondad de ajuste

Si aplicamos el test $\chi^2$ de bondad de ajuste, tenemos que el estadístico de contraste será:
$$
\chi^2_i = \sum_{j=1}^{J} \frac{(\mbox{frec. empíricas}-\mbox{frec. teóricas})^2}{\mbox{frec. teóricas}} =\sum_{j=1}^{J} \frac{\left(n_{ij}-\frac{n_{i\bullet} n_{\bullet j}}{n}\right)^2}{\frac{n_{i\bullet} n_{\bullet J}}{n}}.
$$
Ahora bien, tenemos en total $i$ filas. Por tanto, tenemos que sumar el estadístico anterior para todas las filas:
$$
\chi^2 =\sum_{i=1}^I\chi^2_i =\sum_{i=1}^I\sum_{j=1}^{J} \frac{\left(n_{ij}-\frac{n_{i\bullet} n_{\bullet j}}{n}\right)^2}{\frac{n_{i\bullet} n_{\bullet J}}{n}}.
$$

## Contraste de homogeneidad como un contraste de bondad de ajuste

Observemos que nos queda la misma expresión que el **estadístico de contraste** que en el **contraste de independencia.**

Por tanto, desde el punto de vista de cómputo o de cálculo, realizar un **contraste de independencia** o de **homogeneidad** sería lo mismo.

Ahora bien, desde el punto de vista de diseño de experimentos, no. 

## Contraste de homogeneidad como un contraste de bondad de ajuste

Recordemos que en un **contraste de independencia** se toma una **muestra transversal** de la población. En cambio, en un **contraste de homogeneidad** se  escoge una de las variables (para todo el estudio realizado, sería la variable $X$) y para cada uno de sus posibles valores se toma una muestra aleatoria, de tamaño prefijado, de individuos con ese valor para esa variable; su unión forma una **muestra estratificada** en el sentido que hemos visto en la sección de Muestreo.

## Ejemplo
<div class="example">
**Ejemplo del estudio del número de crías de una loba y la zona donde vive**

Recordemos que la tabla de contingencia en este ejemplo era:
<div class="center">
$X/Y$ | $Y_1$ | $Y_2$ | $Y_3$ | $Y_4$ | $n_{i\bullet}$|
|---|---|---|---|---|---|
|$X_1$ | 5   | 8   | 15  | 22   | 50 |
|$X_2$ | 20 |26  |46   | 8  | 100|
|$X_3$ | 15  | 10  | 15   | 10   | 50 | 
|$n_{\bullet j}$ | 40 | 44 | 76 | 40 | 200 |  
</div>

</div>

## Ejemplo
<div class="example">
Recordemos que la variable $X$ representaba la zona donde vive la loba y la variable $Y$, el número de crías.

Los valores de $X$ eran: $X_1=$"Norte", $X_2=$"Centro" y $X_3=$"Sur".

Los valores de $Y$ eran:
$Y_1=$" Dos o menos", $Y_2=$" Entre tres y cinco",  $Y_3=$"Entre seis y ocho" y $Y_4=$"Nueve  o más".

El contraste de homogeneidad consiste en este caso en testear si la distribución de la variable $Y$, número de crías, es la misma para los tres valores de la variable $X$. 

Para que dicho estudio tenga sentido (desde el punto de vista de la homogeneidad), tendremos que **estratificar** primero la población de las lobas según los valores de la variable $X$. Tendremos que elegir un número prefijado de lobas que vivan en el norte, un número prefijado de lobas que vivan en el centro y un número prefijado de lobas que vivan en el sur. 

Según los datos de la tabla anterior, se eligen aleatoriamente 50 lobas que viven en el norte, 100 lobas que viven en el centro y 50 lobas que viven en el sur. Fijaos que estos tres números se fijan antes de realizar los tres muestreos, cosa que no pasaba en el contraste de independencia. En dicho contraste, se fijaba un sólo número que sería el número total de lobas a clasificar.
</div>

## Ejemplo
<div class="example">
El contraste realizado en `R` era el siguiente:
```{r}
chisq.test(matrix(c(5,20,15,8,26,10,15,46,15,22,8,10),3,4))
```

Como el p-valor es muy pequeño, concluimos que tenemos indicios suficientes para rechazar que la distribución del número de crías de las lobas
es la misma para las tres zonas donde viven.
</div>


## Guía rápida


 
* `table` calcula tablas de contingencia de frecuencias absolutas.

* `prop.table` calcula tablas de contingencia de frecuencias relativas.

* `addmargins` sirve para añadir  a una `table` una fila o una columna obtenidas aplicando una función a todas las columnas o a todas las filas de la tabla, respectivamente. Sus parámetros principales son:
 
    * `margin`: igualado a `1`, se aplica la función por columnas, añadiendo una nueva fila; igualado a `2`, se aplica la función por filas, añadiendo una nueva columna; 
igualado a `c(1,2)`, que es su valor por defecto,  hace ambas cosas.

    * `FUN`:  la función que se aplica a las filas o columnas; su valor por defecto es `sum`.

## Guía rápida

* `colSums`  calcula un vector con las sumas de las columnas de una matriz o una tabla.

* `rowSums`   calcula un vector con las sumas de las filas de una matriz o una tabla.

* `chisq.test` sirve para realizar tests $\chi^2$ de independencia y homogeneidad. El resultado es una `list` formada, entre otros, por los objetos siguientes:  `statistic` (el valor del estadístico $X^2$), `parameter` (los grados de libertad) y  `p.value` (el p-valor). Sus parámetros principales en el contexto de esta lección son:
 
    * `simulate.p.value`: igualado a `TRUE`, calcula el p-valor mediante simulaciones.
    * `B`: en este último caso, permite especificar el número de simulaciones.
 
